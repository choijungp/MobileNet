{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\"\"\"Contains utilities for downloading and converting datasets.\"\"\"\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import tarfile\n",
        "\n",
        "from six.moves import urllib\n",
        "import tensorflow as tf\n",
        "\n",
        "LABELS_FILENAME = 'labels.txt'\n",
        "\n",
        "\n",
        "def int64_feature(values):\n",
        "  \"\"\"Returns a TF-Feature of int64s.\n",
        "  Args:\n",
        "    values: A scalar or list of values.\n",
        "  Returns:\n",
        "    a TF-Feature.\n",
        "  \"\"\"\n",
        "  if not isinstance(values, (tuple, list)):\n",
        "    values = [values]\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=values))\n",
        "\n",
        "\n",
        "def float_feature(value):\n",
        "    \"\"\"Wrapper for inserting float features into Example proto.\n",
        "    \"\"\"\n",
        "    if not isinstance(value, list):\n",
        "        value = [value]\n",
        "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
        "\n",
        "\n",
        "def bytes_feature(value):\n",
        "    \"\"\"Wrapper for inserting bytes features into Example proto.\n",
        "    \"\"\"\n",
        "    if not isinstance(value, list):\n",
        "        value = [value]\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n",
        "\n",
        "\n",
        "def image_to_tfexample(image_data, image_format, height, width, class_id):\n",
        "  return tf.train.Example(features=tf.train.Features(feature={\n",
        "      'image/encoded': bytes_feature(image_data),\n",
        "      'image/format': bytes_feature(image_format),\n",
        "      'image/class/label': int64_feature(class_id),\n",
        "      'image/height': int64_feature(height),\n",
        "      'image/width': int64_feature(width),\n",
        "  }))\n",
        "\n",
        "\n",
        "def download_and_uncompress_tarball(tarball_url, dataset_dir):\n",
        "  \"\"\"Downloads the `tarball_url` and uncompresses it locally.\n",
        "  Args:\n",
        "    tarball_url: The URL of a tarball file.\n",
        "    dataset_dir: The directory where the temporary files are stored.\n",
        "  \"\"\"\n",
        "  filename = tarball_url.split('/')[-1]\n",
        "  filepath = os.path.join(dataset_dir, filename)\n",
        "\n",
        "  def _progress(count, block_size, total_size):\n",
        "    sys.stdout.write('\\r>> Downloading %s %.1f%%' % (\n",
        "        filename, float(count * block_size) / float(total_size) * 100.0))\n",
        "    sys.stdout.flush()\n",
        "  filepath, _ = urllib.request.urlretrieve(tarball_url, filepath, _progress)\n",
        "  print()\n",
        "  statinfo = os.stat(filepath)\n",
        "  print('Successfully downloaded', filename, statinfo.st_size, 'bytes.')\n",
        "  tarfile.open(filepath, 'r:gz').extractall(dataset_dir)\n",
        "\n",
        "\n",
        "def write_label_file(labels_to_class_names, dataset_dir,\n",
        "                     filename=LABELS_FILENAME):\n",
        "  \"\"\"Writes a file with the list of class names.\n",
        "  Args:\n",
        "    labels_to_class_names: A map of (integer) labels to class names.\n",
        "    dataset_dir: The directory in which the labels file should be written.\n",
        "    filename: The filename where the class names are written.\n",
        "  \"\"\"\n",
        "  labels_filename = os.path.join(dataset_dir, filename)\n",
        "  with tf.gfile.Open(labels_filename, 'w') as f:\n",
        "    for label in labels_to_class_names:\n",
        "      class_name = labels_to_class_names[label]\n",
        "      f.write('%d:%s\\n' % (label, class_name))\n",
        "\n",
        "\n",
        "def has_labels(dataset_dir, filename=LABELS_FILENAME):\n",
        "  \"\"\"Specifies whether or not the dataset directory contains a label map file.\n",
        "  Args:\n",
        "    dataset_dir: The directory in which the labels file is found.\n",
        "    filename: The filename where the class names are written.\n",
        "  Returns:\n",
        "    `True` if the labels file exists and `False` otherwise.\n",
        "  \"\"\"\n",
        "  return tf.gfile.Exists(os.path.join(dataset_dir, filename))\n",
        "\n",
        "\n",
        "def read_label_file(dataset_dir, filename=LABELS_FILENAME):\n",
        "  \"\"\"Reads the labels file and returns a mapping from ID to class name.\n",
        "  Args:\n",
        "    dataset_dir: The directory in which the labels file is found.\n",
        "    filename: The filename where the class names are written.\n",
        "  Returns:\n",
        "    A map from a label (integer) to class name.\n",
        "  \"\"\"\n",
        "  labels_filename = os.path.join(dataset_dir, filename)\n",
        "  with tf.gfile.Open(labels_filename, 'r') as f:\n",
        "    lines = f.read().decode()\n",
        "  lines = lines.split('\\n')\n",
        "  lines = filter(None, lines)\n",
        "\n",
        "  labels_to_class_names = {}\n",
        "  for line in lines:\n",
        "    index = line.index(':')\n",
        "    labels_to_class_names[int(line[:index])] = line[index+1:]\n",
        "  return labels_to_class_names"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}