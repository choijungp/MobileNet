{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\"\"\"Provides data for the Cifar10 dataset.\n",
        "The dataset scripts used to create the dataset can be found at:\n",
        "tensorflow/models/slim/datasets/download_and_convert_cifar10.py\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "from datasets import dataset_utils\n",
        "\n",
        "slim = tf.contrib.slim\n",
        "\n",
        "_FILE_PATTERN = 'cifar10_%s.tfrecord'\n",
        "\n",
        "SPLITS_TO_SIZES = {'train': 50000, 'test': 10000}\n",
        "\n",
        "_NUM_CLASSES = 10\n",
        "\n",
        "_ITEMS_TO_DESCRIPTIONS = {\n",
        "    'image': 'A [32 x 32 x 3] color image.',\n",
        "    'label': 'A single integer between 0 and 9',\n",
        "}\n",
        "\n",
        "\n",
        "def get_split(split_name, dataset_dir, file_pattern=None, reader=None):\n",
        "  \"\"\"Gets a dataset tuple with instructions for reading cifar10.\n",
        "  Args:\n",
        "    split_name: A train/test split name.\n",
        "    dataset_dir: The base directory of the dataset sources.\n",
        "    file_pattern: The file pattern to use when matching the dataset sources.\n",
        "      It is assumed that the pattern contains a '%s' string so that the split\n",
        "      name can be inserted.\n",
        "    reader: The TensorFlow reader type.\n",
        "  Returns:\n",
        "    A `Dataset` namedtuple.\n",
        "  Raises:\n",
        "    ValueError: if `split_name` is not a valid train/test split.\n",
        "  \"\"\"\n",
        "  if split_name not in SPLITS_TO_SIZES:\n",
        "    raise ValueError('split name %s was not recognized.' % split_name)\n",
        "\n",
        "  if not file_pattern:\n",
        "    file_pattern = _FILE_PATTERN\n",
        "  file_pattern = os.path.join(dataset_dir, file_pattern % split_name)\n",
        "\n",
        "  # Allowing None in the signature so that dataset_factory can use the default.\n",
        "  if not reader:\n",
        "    reader = tf.TFRecordReader\n",
        "\n",
        "  keys_to_features = {\n",
        "      'image/encoded': tf.FixedLenFeature((), tf.string, default_value=''),\n",
        "      'image/format': tf.FixedLenFeature((), tf.string, default_value='png'),\n",
        "      'image/class/label': tf.FixedLenFeature(\n",
        "          [], tf.int64, default_value=tf.zeros([], dtype=tf.int64)),\n",
        "  }\n",
        "\n",
        "  items_to_handlers = {\n",
        "      'image': slim.tfexample_decoder.Image(shape=[32, 32, 3]),\n",
        "      'label': slim.tfexample_decoder.Tensor('image/class/label'),\n",
        "  }\n",
        "\n",
        "  decoder = slim.tfexample_decoder.TFExampleDecoder(\n",
        "      keys_to_features, items_to_handlers)\n",
        "\n",
        "  labels_to_names = None\n",
        "  if dataset_utils.has_labels(dataset_dir):\n",
        "    labels_to_names = dataset_utils.read_label_file(dataset_dir)\n",
        "\n",
        "  return slim.dataset.Dataset(\n",
        "      data_sources=file_pattern,\n",
        "      reader=reader,\n",
        "      decoder=decoder,\n",
        "      num_samples=SPLITS_TO_SIZES[split_name],\n",
        "      items_to_descriptions=_ITEMS_TO_DESCRIPTIONS,\n",
        "      num_classes=_NUM_CLASSES,\n",
        "      labels_to_names=labels_to_names)"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}