{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Copyright 2015 Paul Balanca. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\"\"\"Provides data for the Pascal VOC Dataset (images + annotations).\n",
        "\"\"\"\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from datasets import dataset_utils\n",
        "\n",
        "slim = tf.contrib.slim\n",
        "\n",
        "VOC_LABELS = {\n",
        "    'none': (0, 'Background'),\n",
        "    'aeroplane': (1, 'Vehicle'),\n",
        "    'bicycle': (2, 'Vehicle'),\n",
        "    'bird': (3, 'Animal'),\n",
        "    'boat': (4, 'Vehicle'),\n",
        "    'bottle': (5, 'Indoor'),\n",
        "    'bus': (6, 'Vehicle'),\n",
        "    'car': (7, 'Vehicle'),\n",
        "    'cat': (8, 'Animal'),\n",
        "    'chair': (9, 'Indoor'),\n",
        "    'cow': (10, 'Animal'),\n",
        "    'diningtable': (11, 'Indoor'),\n",
        "    'dog': (12, 'Animal'),\n",
        "    'horse': (13, 'Animal'),\n",
        "    'motorbike': (14, 'Vehicle'),\n",
        "    'person': (15, 'Person'),\n",
        "    'pottedplant': (16, 'Indoor'),\n",
        "    'sheep': (17, 'Animal'),\n",
        "    'sofa': (18, 'Indoor'),\n",
        "    'train': (19, 'Vehicle'),\n",
        "    'tvmonitor': (20, 'Indoor'),\n",
        "}\n",
        "\n",
        "\n",
        "def get_split(split_name, dataset_dir, file_pattern, reader,\n",
        "              items_to_descriptions, num_classes):\n",
        "    \"\"\"Gets a dataset tuple with instructions for reading Pascal VOC dataset.\n",
        "    Args:\n",
        "      split_name: A trainval/test split name.\n",
        "      dataset_dir: The base directory of the dataset sources.\n",
        "      file_pattern: The file pattern to use when matching the dataset sources.\n",
        "        It is assumed that the pattern contains a '%s' string so that the split\n",
        "        name can be inserted.\n",
        "      reader: The TensorFlow reader type.\n",
        "    Returns:\n",
        "      A `Dataset` namedtuple.\n",
        "    Raises:\n",
        "        ValueError: if `split_name` is not a valid train/test split.\n",
        "    \"\"\"\n",
        "    if split_name not in ['trainval', 'test']:\n",
        "        raise ValueError('split name %s was not recognized.' % split_name)\n",
        "    file_pattern = os.path.join(dataset_dir, file_pattern % split_name)\n",
        "\n",
        "    # Allowing None in the signature so that dataset_factory can use the default.\n",
        "    if reader is None:\n",
        "        reader = tf.TFRecordReader\n",
        "    # Features in Pascal VOC TFRecords.\n",
        "    keys_to_features = {\n",
        "        'image/encoded': tf.FixedLenFeature((), tf.string, default_value=''),\n",
        "        'image/format': tf.FixedLenFeature((), tf.string, default_value='jpeg'),\n",
        "        'image/height': tf.FixedLenFeature([1], tf.int64),\n",
        "        'image/width': tf.FixedLenFeature([1], tf.int64),\n",
        "        'image/channels': tf.FixedLenFeature([1], tf.int64),\n",
        "        'image/shape': tf.FixedLenFeature([3], tf.int64),\n",
        "        'image/object/bbox/xmin': tf.VarLenFeature(dtype=tf.float32),\n",
        "        'image/object/bbox/ymin': tf.VarLenFeature(dtype=tf.float32),\n",
        "        'image/object/bbox/xmax': tf.VarLenFeature(dtype=tf.float32),\n",
        "        'image/object/bbox/ymax': tf.VarLenFeature(dtype=tf.float32),\n",
        "        'image/object/bbox/label': tf.VarLenFeature(dtype=tf.int64),\n",
        "        'image/object/bbox/difficult': tf.VarLenFeature(dtype=tf.int64),\n",
        "        'image/object/bbox/truncated': tf.VarLenFeature(dtype=tf.int64),\n",
        "    }\n",
        "    items_to_handlers = {\n",
        "        'image': slim.tfexample_decoder.Image('image/encoded', 'image/format'),\n",
        "        'shape': slim.tfexample_decoder.Tensor('image/shape'),\n",
        "        'object/bbox': slim.tfexample_decoder.BoundingBox(\n",
        "                ['ymin', 'xmin', 'ymax', 'xmax'], 'image/object/bbox/'),\n",
        "        'object/label': slim.tfexample_decoder.Tensor('image/object/bbox/label'),\n",
        "        'object/difficult': slim.tfexample_decoder.Tensor('image/object/bbox/difficult'),\n",
        "        'object/truncated': slim.tfexample_decoder.Tensor('image/object/bbox/truncated'),\n",
        "    }\n",
        "    decoder = slim.tfexample_decoder.TFExampleDecoder(\n",
        "        keys_to_features, items_to_handlers)\n",
        "\n",
        "    labels_to_names = None\n",
        "    if dataset_utils.has_labels(dataset_dir):\n",
        "        labels_to_names = dataset_utils.read_label_file(dataset_dir)\n",
        "    # else:\n",
        "    #     labels_to_names = create_readable_names_for_imagenet_labels()\n",
        "    #     dataset_utils.write_label_file(labels_to_names, dataset_dir)\n",
        "\n",
        "    return slim.dataset.Dataset(\n",
        "            data_sources=file_pattern,\n",
        "            reader=reader,\n",
        "            decoder=decoder,\n",
        "            num_samples=split_to_sizes[split_name],\n",
        "            items_to_descriptions=items_to_descriptions,\n",
        "            num_classes=num_classes,\n",
        "            labels_to_names=labels_to_names)"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}