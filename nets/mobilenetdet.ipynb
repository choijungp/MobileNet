{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.contrib.slim as slim\n",
        "import numpy as np\n",
        "from configs.kitti_config import config\n",
        "\n",
        "\n",
        "def xywh_to_yxyx(bbox):\n",
        "  shape = bbox.get_shape().as_list()\n",
        "  _axis = 1 if len(shape) > 1 else 0\n",
        "  [x, y, w, h] = tf.unstack(bbox, axis=_axis)\n",
        "  y_min = y - 0.5 * h\n",
        "  x_min = x - 0.5 * w\n",
        "  y_max = y + 0.5 * h\n",
        "  x_max = x + 0.5 * w\n",
        "  return tf.stack([y_min, x_min, y_max, x_max], axis=_axis)\n",
        "\n",
        "\n",
        "def yxyx_to_xywh_(bbox):\n",
        "  y_min = bbox[:, 0]\n",
        "  x_min = bbox[:, 1]\n",
        "  y_max = bbox[:, 2]\n",
        "  x_max = bbox[:, 3]\n",
        "  x = (x_min + x_max) * 0.5\n",
        "  y = (y_min + y_max) * 0.5\n",
        "  w = x_max - x_min\n",
        "  h = y_max - y_min\n",
        "  return tf.stack([x, y, w, h], axis=1)\n",
        "\n",
        "\n",
        "def scale_bboxes(bbox, img_shape):\n",
        "  \"\"\"Scale bboxes to [0, 1). bbox format [ymin, xmin, ymax, xmax]\n",
        "  Args:\n",
        "    bbox: 2-D with shape '[num_bbox, 4]'\n",
        "    img_shape: 1-D with shape '[4]'\n",
        "  Return:\n",
        "    sclaed_bboxes: scaled bboxes\n",
        "  \"\"\"\n",
        "  img_h = tf.cast(img_shape[0], dtype=tf.float32)\n",
        "  img_w = tf.cast(img_shape[1], dtype=tf.float32)\n",
        "  shape = bbox.get_shape().as_list()\n",
        "  _axis = 1 if len(shape) > 1 else 0\n",
        "  [y_min, x_min, y_max, x_max] = tf.unstack(bbox, axis=_axis)\n",
        "  y_1 = tf.truediv(y_min, img_h)\n",
        "  x_1 = tf.truediv(x_min, img_w)\n",
        "  y_2 = tf.truediv(y_max, img_h)\n",
        "  x_2 = tf.truediv(x_max, img_w)\n",
        "  return tf.stack([y_1, x_1, y_2, x_2], axis=_axis)\n",
        "\n",
        "\n",
        "def iou(bbox_1, bbox_2):\n",
        "  \"\"\"Compute iou of a box with another box. Box format '[y_min, x_min, y_max, x_max]'.\n",
        "  Args:\n",
        "    bbox_1: 1-D with shape `[4]`.\n",
        "    bbox_2: 1-D with shape `[4]`.\n",
        "  Returns:\n",
        "    IOU\n",
        "  \"\"\"\n",
        "  lr = tf.minimum(bbox_1[3], bbox_2[3]) - tf.maximum(bbox_1[1], bbox_2[1])\n",
        "  tb = tf.minimum(bbox_1[2], bbox_2[2]) - tf.maximum(bbox_1[0], bbox_2[0])\n",
        "  lr = tf.maximum(lr, lr * 0)\n",
        "  tb = tf.maximum(tb, tb * 0)\n",
        "  intersection = tf.multiply(tb, lr)\n",
        "  union = tf.subtract(\n",
        "    tf.multiply((bbox_1[3] - bbox_1[1]), (bbox_1[2] - bbox_1[0])) +\n",
        "    tf.multiply((bbox_2[3] - bbox_2[1]), (bbox_2[2] - bbox_2[0])),\n",
        "    intersection\n",
        "  )\n",
        "  iou = tf.div(intersection, union)\n",
        "  return iou\n",
        "\n",
        "\n",
        "def batch_iou(bboxes, bbox):\n",
        "  \"\"\"Compute iou of a batch of boxes with another box. Box format '[y_min, x_min, y_max, x_max]'.\n",
        "  Args:\n",
        "    bboxes: A batch of boxes. 2-D with shape `[B, 4]`.\n",
        "    bbox: A single box. 1-D with shape `[4]`.\n",
        "  Returns:\n",
        "    Batch of IOUs\n",
        "  \"\"\"\n",
        "  lr = tf.maximum(\n",
        "    tf.minimum(bboxes[:, 3], bbox[3]) -\n",
        "    tf.maximum(bboxes[:, 1], bbox[1]),\n",
        "    0\n",
        "  )\n",
        "  tb = tf.maximum(\n",
        "    tf.minimum(bboxes[:, 2], bbox[2]) -\n",
        "    tf.maximum(bboxes[:, 0], bbox[0]),\n",
        "    0\n",
        "  )\n",
        "  intersection = tf.multiply(tb, lr)\n",
        "  union = tf.subtract(\n",
        "    tf.multiply((bboxes[:, 3] - bboxes[:, 1]), (bboxes[:, 2] - bboxes[:, 0])) +\n",
        "    tf.multiply((bbox[3] - bbox[1]), (bbox[2] - bbox[0])),\n",
        "    intersection\n",
        "  )\n",
        "  iou = tf.div(intersection, union)\n",
        "  return iou\n",
        "\n",
        "\n",
        "def batch_iou_(anchors, bboxes):\n",
        "  \"\"\" Compute iou of two batch of boxes. Box format '[y_min, x_min, y_max, x_max]'.\n",
        "  Args:\n",
        "    anchors: know shape\n",
        "    bboxes: dynamic shape\n",
        "  Return:\n",
        "    ious: 2-D with shape '[num_bboxes, num_anchors]'\n",
        "    indices: [num_bboxes, 1]\n",
        "  \"\"\"\n",
        "  num_anchors = anchors.get_shape().as_list()[0]\n",
        "  ious_list = []\n",
        "  for i in range(num_anchors):\n",
        "    anchor = anchors[i]\n",
        "    _ious = batch_iou(bboxes, anchor)\n",
        "    ious_list.append(_ious)\n",
        "  ious = tf.stack(ious_list, axis=0)\n",
        "  ious = tf.transpose(ious)\n",
        "\n",
        "  indices = tf.arg_max(ious, dimension=1)\n",
        "\n",
        "  return ious, indices\n",
        "\n",
        "\n",
        "def batch_iou_fast(anchors, bboxes):\n",
        "  \"\"\" Compute iou of two batch of boxes. Box format '[y_min, x_min, y_max, x_max]'.\n",
        "  Args:\n",
        "    anchors: know shape\n",
        "    bboxes: dynamic shape\n",
        "  Return:\n",
        "    ious: 2-D with shape '[num_bboxes, num_anchors]'\n",
        "    indices: [num_bboxes, 1]\n",
        "  \"\"\"\n",
        "  num_anchors = anchors.get_shape().as_list()[0]\n",
        "  tensor_num_bboxes = tf.shape(bboxes)[0]\n",
        "  indices = tf.reshape(tf.range(tensor_num_bboxes), shape=[-1, 1])\n",
        "  indices = tf.reshape(tf.stack([indices]*num_anchors, axis=1), shape=[-1, 1])\n",
        "  bboxes_m = tf.gather_nd(bboxes, indices)\n",
        "\n",
        "  anchors_m = tf.tile(anchors, [tensor_num_bboxes, 1])\n",
        "\n",
        "  lr = tf.maximum(\n",
        "    tf.minimum(bboxes_m[:, 3], anchors_m[:, 3]) -\n",
        "    tf.maximum(bboxes_m[:, 1], anchors_m[:, 1]),\n",
        "    0\n",
        "  )\n",
        "  tb = tf.maximum(\n",
        "    tf.minimum(bboxes_m[:, 2], anchors_m[:, 2]) -\n",
        "    tf.maximum(bboxes_m[:, 0], anchors_m[:, 0]),\n",
        "    0\n",
        "  )\n",
        "  intersection = tf.multiply(tb, lr)\n",
        "  union = tf.subtract(\n",
        "    tf.multiply((bboxes_m[:, 3] - bboxes_m[:, 1]), (bboxes_m[:, 2] - bboxes_m[:, 0])) +\n",
        "    tf.multiply((anchors_m[:, 3] - anchors_m[:, 1]), (anchors_m[:, 2] - anchors_m[:, 0])),\n",
        "    intersection\n",
        "  )\n",
        "  ious = tf.div(intersection, union)\n",
        "\n",
        "  ious = tf.reshape(ious, shape=[tensor_num_bboxes, num_anchors])\n",
        "\n",
        "  indices = tf.arg_max(ious, dimension=1)\n",
        "\n",
        "  return ious, indices\n",
        "\n",
        "\n",
        "def compute_delta(gt_box, anchor):\n",
        "  \"\"\"Compute delta, anchor+delta = gt_box. Box format '[cx, cy, w, h]'.\n",
        "  Args:\n",
        "    gt_box: A batch of boxes. 2-D with shape `[B, 4]`.\n",
        "    anchor: A single box. 1-D with shape `[4]`.\n",
        "  Returns:\n",
        "    delta: 1-D tensor with shape '[4]', [dx, dy, dw, dh]\n",
        "  \"\"\"\n",
        "  delta_x = (gt_box[0] - anchor[0]) / gt_box[2]\n",
        "  delta_y = (gt_box[1] - anchor[1]) / gt_box[3]\n",
        "  delta_w = tf.log(gt_box[2] / anchor[2])\n",
        "  delta_h = tf.log(gt_box[3] / anchor[3])\n",
        "  return tf.stack([delta_x, delta_y, delta_w, delta_h], axis=0)\n",
        "\n",
        "\n",
        "def batch_delta(bboxes, anchors):\n",
        "  \"\"\"\n",
        "  Args:\n",
        "     bboxes: [num_bboxes, 4]\n",
        "     anchors: [num_bboxes, 4]\n",
        "  Return:\n",
        "    deltas: [num_bboxes, 4]\n",
        "  \"\"\"\n",
        "  bbox_x, bbox_y, bbox_w, bbox_h = tf.unstack(bboxes, axis=1)\n",
        "  anchor_x, anchor_y, anchor_w, anchor_h = tf.unstack(anchors, axis=1)\n",
        "  delta_x = (bbox_x - anchor_x) / bbox_w\n",
        "  delta_y = (bbox_y - anchor_y) / bbox_h\n",
        "  delta_w = tf.log(bbox_w / anchor_w)\n",
        "  delta_h = tf.log(bbox_h / anchor_h)\n",
        "  return tf.stack([delta_x, delta_y, delta_w, delta_h], axis=1)\n",
        "\n",
        "\n",
        "# TODO(shizehao): improve speed, use sparse tensor instead\n",
        "def encode_annos(image, labels, bboxes, anchors, num_classes):\n",
        "  \"\"\"Encode annotations for losses computations.\n",
        "  All the output tensors have a fix shape(none dynamic dimention).\n",
        "  Args:\n",
        "    image: 4-D with shape `[H, W, C]`.\n",
        "    b_labels: 2-D with shape `[num_bounding_boxes]`.\n",
        "    b_bboxes: 3-D with shape `[num_bounding_boxes, 4]`. Scaled.\n",
        "    anchors: 4-D tensor with shape `[fea_h, fea_w, num_anchors, 4]`\n",
        "  Returns:\n",
        "    input_mask: 2-D with shape `[num_anchors, 1]`, indicate which anchor to be used to cal loss.\n",
        "    labels_input: 2-D with shape `[num_anchors, num_classes]`, one hot encode for every anchor.\n",
        "    box_delta_input: 2-D with shape `[num_anchors, 4]`.\n",
        "    box_input: 2-D with shape '[num_anchors, 4]'.\n",
        "  \"\"\"\n",
        "  anchors_shape = anchors.get_shape().as_list()\n",
        "  fea_h = anchors_shape[0]\n",
        "  fea_w = anchors_shape[1]\n",
        "  num_anchors = anchors_shape[2] * fea_h * fea_w\n",
        "  anchors = tf.reshape(anchors, [num_anchors, 4])  # reshape anchors\n",
        "\n",
        "  # Cal iou, find the target anchor\n",
        "  _anchors = xywh_to_yxyx(anchors)\n",
        "  ious, indices = batch_iou_fast(_anchors, bboxes)\n",
        "  indices = tf.reshape(indices, shape=[-1, 1])\n",
        "\n",
        "  target_anchors = tf.gather(anchors, indices)\n",
        "  target_anchors = tf.squeeze(target_anchors, axis=1)\n",
        "  delta = batch_delta(yxyx_to_xywh_(bboxes), target_anchors)\n",
        "\n",
        "  # bbox\n",
        "  box_input = tf.scatter_nd(\n",
        "    indices,\n",
        "    bboxes,\n",
        "    shape=[num_anchors, 4]\n",
        "  )\n",
        "  # label\n",
        "  labels_input = tf.scatter_nd(\n",
        "    indices,\n",
        "    tf.one_hot(labels, num_classes),\n",
        "    shape=[num_anchors, num_classes]\n",
        "  )\n",
        "  # anchor mask\n",
        "  onehot_anchor = tf.one_hot(indices, num_anchors)\n",
        "  onehot_anchor = tf.squeeze(onehot_anchor, axis=1)\n",
        "  print(\"indices shape:\", indices.get_shape().as_list())\n",
        "  print(\"one hot anchors shape:\", onehot_anchor.get_shape().as_list())\n",
        "  input_mask = tf.reduce_sum(onehot_anchor, axis=0)\n",
        "  input_mask = tf.reshape(input_mask, shape=[-1, 1])\n",
        "  # delta\n",
        "  box_delta_input = tf.scatter_nd(\n",
        "    indices,\n",
        "    delta,\n",
        "    shape=[num_anchors, 4]\n",
        "  )\n",
        "\n",
        "  return input_mask, labels_input, box_delta_input, box_input\n",
        "\n",
        "\n",
        "# TODO(shizehao): align anchor center to the grid\n",
        "def set_anchors(img_shape, fea_shape):\n",
        "  \"\"\"Set anchors.\n",
        "  Args:\n",
        "    img_shape: 1-D list with shape `[2]`.\n",
        "    fea_shape: 1-D list with shape `[2]`.\n",
        "  Returns:\n",
        "    anchors: 4-D tensor with shape `[fea_h, fea_w, num_anchors, 4]`\n",
        "  \"\"\"\n",
        "  H = fea_shape[0]\n",
        "  W = fea_shape[1]\n",
        "  B = config.NUM_ANCHORS\n",
        "\n",
        "  anchor_shape = tf.constant(config.ANCHOR_SHAPE, dtype=tf.float32)\n",
        "  anchor_shapes = tf.reshape(\n",
        "    tf.concat(\n",
        "      [anchor_shape for i in range(W * H)],\n",
        "      0\n",
        "    ),\n",
        "    [H, W, B, 2]\n",
        "  )\n",
        "\n",
        "  center_x = tf.truediv(\n",
        "    tf.range(1, W + 1, 1, dtype=tf.float32),  # * img_w,\n",
        "    float(W + 1)\n",
        "  )\n",
        "  center_x = tf.concat(\n",
        "    [center_x for i in range(H * B)], 0\n",
        "  )\n",
        "  center_x = tf.reshape(center_x, [B, H, W])\n",
        "  center_x = tf.transpose(center_x, (1, 2, 0))\n",
        "  center_x = tf.reshape(center_x, [H, W, B, 1])\n",
        "\n",
        "  center_y = tf.truediv(\n",
        "    tf.range(1, H + 1, 1, dtype=tf.float32),  # * img_h,\n",
        "    float(H + 1)\n",
        "  )\n",
        "  center_y = tf.concat(\n",
        "    [center_y for i in range(W * B)], 0\n",
        "  )\n",
        "  center_y = tf.reshape(center_y, [B, W, H])\n",
        "  center_y = tf.transpose(center_y, (2, 1, 0))\n",
        "  center_y = tf.reshape(center_y, [H, W, B, 1])\n",
        "\n",
        "  anchors = tf.concat([center_x, center_y, anchor_shapes], 3)\n",
        "\n",
        "  return anchors\n",
        "\n",
        "\n",
        "def interpre_prediction(prediction, input_mask, anchors, box_input, fea_h, fea_w):\n",
        "  # probability\n",
        "  batch_size = tf.shape(input_mask)[0]\n",
        "  num_class_probs = config.NUM_ANCHORS * config.NUM_CLASSES\n",
        "  pred_class_probs = tf.reshape(\n",
        "    tf.nn.softmax(\n",
        "      tf.reshape(\n",
        "        prediction[:, :, :, :num_class_probs],\n",
        "        [-1, config.NUM_CLASSES]\n",
        "      )\n",
        "    ),\n",
        "    [batch_size, config.NUM_ANCHORS * fea_h * fea_w, config.NUM_CLASSES],\n",
        "    name='pred_class_probs'\n",
        "  )\n",
        "\n",
        "  # confidence\n",
        "  num_confidence_scores = config.NUM_ANCHORS + num_class_probs\n",
        "  pred_conf = tf.sigmoid(\n",
        "    tf.reshape(\n",
        "      prediction[:, :, :, num_class_probs:num_confidence_scores],\n",
        "      [batch_size, config.NUM_ANCHORS * fea_h * fea_w]\n",
        "    ),\n",
        "    name='pred_confidence_score'\n",
        "  )\n",
        "\n",
        "  # bbox_delta\n",
        "  pred_box_delta = tf.reshape(\n",
        "    prediction[:, :, :, num_confidence_scores:],\n",
        "    [batch_size, config.NUM_ANCHORS * fea_h * fea_w, 4],\n",
        "    name='bbox_delta'\n",
        "  )\n",
        "\n",
        "  # number of object. Used to normalize bbox and classification loss\n",
        "  num_objects = tf.reduce_sum(input_mask, name='num_objects')\n",
        "\n",
        "  with tf.variable_scope('bbox') as scope:\n",
        "    with tf.variable_scope('stretching'):\n",
        "      delta_x, delta_y, delta_w, delta_h = tf.unstack(\n",
        "        pred_box_delta, axis=2)\n",
        "\n",
        "      anchor_x = anchors[:, 0]\n",
        "      anchor_y = anchors[:, 1]\n",
        "      anchor_w = anchors[:, 2]\n",
        "      anchor_h = anchors[:, 3]\n",
        "\n",
        "      box_center_x = tf.identity(\n",
        "        anchor_x + delta_x * anchor_w, name='bbox_cx')\n",
        "      box_center_y = tf.identity(\n",
        "        anchor_y + delta_y * anchor_h, name='bbox_cy')\n",
        "      box_width = tf.identity(\n",
        "        anchor_w * safe_exp(delta_w, config.EXP_THRESH),\n",
        "        name='bbox_width')\n",
        "      box_height = tf.identity(\n",
        "        anchor_h * safe_exp(delta_h, config.EXP_THRESH),\n",
        "        name='bbox_height')\n",
        "\n",
        "    with tf.variable_scope('trimming'):\n",
        "      xmins, ymins, xmaxs, ymaxs = bbox_transform(\n",
        "        [box_center_x, box_center_y, box_width, box_height])\n",
        "\n",
        "      # The max x position is mc.IMAGE_WIDTH - 1 since we use zero-based\n",
        "      # pixels. Same for y.\n",
        "      xmins = tf.minimum(\n",
        "        tf.maximum(0.0, xmins), config.IMG_WIDTH - 1.0, name='bbox_xmin')\n",
        "\n",
        "      ymins = tf.minimum(\n",
        "        tf.maximum(0.0, ymins), config.IMG_HEIGHT - 1.0, name='bbox_ymin')\n",
        "\n",
        "      xmaxs = tf.maximum(\n",
        "        tf.minimum(config.IMG_WIDTH - 1.0, xmaxs), 0.0, name='bbox_xmax')\n",
        "\n",
        "      ymaxs = tf.maximum(\n",
        "        tf.minimum(config.IMG_HEIGHT - 1.0, ymaxs), 0.0, name='bbox_ymax')\n",
        "\n",
        "      det_boxes = tf.transpose(\n",
        "        tf.stack(bbox_transform_inv([xmins, ymins, xmaxs, ymaxs])),\n",
        "        (1, 2, 0), name='bbox'\n",
        "      )\n",
        "\n",
        "      with tf.variable_scope('IOU'):\n",
        "        def _tensor_iou(box1, box2):\n",
        "          with tf.variable_scope('intersection'):\n",
        "            xmin = tf.maximum(box1[0], box2[0], name='xmin')\n",
        "            ymin = tf.maximum(box1[1], box2[1], name='ymin')\n",
        "            xmax = tf.minimum(box1[2], box2[2], name='xmax')\n",
        "            ymax = tf.minimum(box1[3], box2[3], name='ymax')\n",
        "\n",
        "            w = tf.maximum(0.0, xmax - xmin, name='inter_w')\n",
        "            h = tf.maximum(0.0, ymax - ymin, name='inter_h')\n",
        "            intersection = tf.multiply(w, h, name='intersection')\n",
        "\n",
        "          with tf.variable_scope('union'):\n",
        "            w1 = tf.subtract(box1[2], box1[0], name='w1')\n",
        "            h1 = tf.subtract(box1[3], box1[1], name='h1')\n",
        "            w2 = tf.subtract(box2[2], box2[0], name='w2')\n",
        "            h2 = tf.subtract(box2[3], box2[1], name='h2')\n",
        "\n",
        "            union = w1 * h1 + w2 * h2 - intersection\n",
        "\n",
        "          return intersection / (union + config.EPSILON) \\\n",
        "                 * tf.reshape(input_mask, [batch_size, config.NUM_ANCHORS * fea_h * fea_w])\n",
        "\n",
        "        # TODO(shizehao): need test\n",
        "        ious = _tensor_iou(\n",
        "          bbox_transform(tf.unstack(det_boxes, axis=2)),\n",
        "          bbox_transform(tf.unstack(box_input, axis=2))\n",
        "        )\n",
        "\n",
        "      with tf.variable_scope('probability') as scope:\n",
        "        probs = tf.multiply(\n",
        "          pred_class_probs,\n",
        "          tf.reshape(pred_conf, [batch_size, config.NUM_ANCHORS * fea_h * fea_w, 1]),\n",
        "          name='final_class_prob'\n",
        "        )\n",
        "\n",
        "        det_probs = tf.reduce_max(probs, 2, name='score')\n",
        "        det_class = tf.argmax(probs, 2, name='class_idx')\n",
        "\n",
        "  return pred_box_delta, pred_class_probs, pred_conf, ious, det_probs, det_boxes, det_class\n",
        "\n",
        "\n",
        "def losses(input_mask, labels, ious, box_delta_input, pred_class_probs, pred_conf, pred_box_delta):\n",
        "  batch_size = tf.shape(input_mask)[0]\n",
        "  num_objects = tf.reduce_sum(input_mask, name='num_objects')\n",
        "  with tf.variable_scope('class_regression') as scope:\n",
        "    # cross-entropy: q * -log(p) + (1-q) * -log(1-p)\n",
        "    # add a small value into log to prevent blowing up\n",
        "    class_loss = tf.truediv(\n",
        "      tf.reduce_sum(\n",
        "        (labels * (-tf.log(pred_class_probs + config.EPSILON))\n",
        "         + (1 - labels) * (-tf.log(1 - pred_class_probs + config.EPSILON)))\n",
        "        * input_mask * config.LOSS_COEF_CLASS),\n",
        "      num_objects,\n",
        "      name='class_loss'\n",
        "    )\n",
        "    tf.losses.add_loss(class_loss)\n",
        "\n",
        "  with tf.variable_scope('confidence_score_regression') as scope:\n",
        "    input_mask_ = tf.reshape(input_mask, [batch_size, config.ANCHORS])\n",
        "    conf_loss = tf.reduce_mean(\n",
        "      tf.reduce_sum(\n",
        "        tf.square((ious - pred_conf))\n",
        "        * (input_mask_ * config.LOSS_COEF_CONF_POS / num_objects\n",
        "           + (1 - input_mask_) * config.LOSS_COEF_CONF_NEG / (config.ANCHORS - num_objects)),\n",
        "        reduction_indices=[1]\n",
        "      ),\n",
        "      name='confidence_loss'\n",
        "    )\n",
        "    tf.losses.add_loss(conf_loss)\n",
        "\n",
        "  with tf.variable_scope('bounding_box_regression') as scope:\n",
        "    bbox_loss = tf.truediv(\n",
        "      tf.reduce_sum(\n",
        "        config.LOSS_COEF_BBOX * tf.square(\n",
        "          input_mask * (pred_box_delta - box_delta_input))),\n",
        "      num_objects,\n",
        "      name='bbox_loss'\n",
        "    )\n",
        "    tf.losses.add_loss(bbox_loss)\n",
        "\n",
        "  # add above losses as well as weight decay losses to form the total loss\n",
        "  loss = tf.add_n(tf.get_collection('losses'), name='total_loss')\n",
        "  return loss\n",
        "\n",
        "\n",
        "def safe_exp(w, thresh):\n",
        "  \"\"\"Safe exponential function for tensors.\"\"\"\n",
        "\n",
        "  slope = np.exp(thresh)\n",
        "  with tf.variable_scope('safe_exponential'):\n",
        "    lin_region = tf.to_float(w > thresh)\n",
        "\n",
        "    lin_out = slope * (w - thresh + 1.)\n",
        "    exp_out = tf.exp(w)\n",
        "\n",
        "    out = lin_region * lin_out + (1. - lin_region) * exp_out\n",
        "  return out\n",
        "\n",
        "\n",
        "def bbox_transform_inv(bbox):\n",
        "  \"\"\"convert a bbox of form [xmin, ymin, xmax, ymax] to [cx, cy, w, h]. Works\n",
        "  for numpy array or list of tensors.\n",
        "  \"\"\"\n",
        "  with tf.variable_scope('bbox_transform_inv') as scope:\n",
        "    xmin, ymin, xmax, ymax = bbox\n",
        "    out_box = [[]] * 4\n",
        "\n",
        "    width = xmax - xmin + 1.0\n",
        "    height = ymax - ymin + 1.0\n",
        "    out_box[0] = xmin + 0.5 * width\n",
        "    out_box[1] = ymin + 0.5 * height\n",
        "    out_box[2] = width\n",
        "    out_box[3] = height\n",
        "\n",
        "  return out_box\n",
        "\n",
        "\n",
        "def bbox_transform(bbox):\n",
        "  \"\"\"convert a bbox of form [cx, cy, w, h] to [xmin, ymin, xmax, ymax]. Works\n",
        "  for numpy array or list of tensors.\n",
        "  \"\"\"\n",
        "  with tf.variable_scope('bbox_transform') as scope:\n",
        "    cx, cy, w, h = bbox\n",
        "    out_box = [[]] * 4\n",
        "    out_box[0] = cx - w / 2\n",
        "    out_box[1] = cy - h / 2\n",
        "    out_box[2] = cx + w / 2\n",
        "    out_box[3] = cy + h / 2\n",
        "\n",
        "  return out_box\n",
        "\n",
        "\n",
        "def mobilenet(inputs,\n",
        "          is_training=True,\n",
        "          width_multiplier=1,\n",
        "          scope='MobileNet'):\n",
        "  def _depthwise_separable_conv(inputs,\n",
        "                                num_pwc_filters,\n",
        "                                width_multiplier,\n",
        "                                sc,\n",
        "                                downsample=False):\n",
        "    \"\"\" Helper function to build the depth-wise separable convolution layer.\n",
        "    \"\"\"\n",
        "    num_pwc_filters = round(num_pwc_filters * width_multiplier)\n",
        "    _stride = 2 if downsample else 1\n",
        "\n",
        "    # skip pointwise by setting num_outputs=None\n",
        "    depthwise_conv = slim.separable_convolution2d(inputs,\n",
        "                                                  num_outputs=None,\n",
        "                                                  stride=_stride,\n",
        "                                                  depth_multiplier=1,\n",
        "                                                  kernel_size=[3, 3],\n",
        "                                                  scope=sc+'/depthwise_conv')\n",
        "\n",
        "    bn = slim.batch_norm(depthwise_conv, scope=sc+'/dw_batch_norm')\n",
        "    pointwise_conv = slim.convolution2d(bn,\n",
        "                                        num_pwc_filters,\n",
        "                                        kernel_size=[1, 1],\n",
        "                                        scope=sc+'/pointwise_conv')\n",
        "    bn = slim.batch_norm(pointwise_conv, scope=sc+'/pw_batch_norm')\n",
        "    return bn\n",
        "\n",
        "  with tf.variable_scope(scope) as sc:\n",
        "    end_points_collection = sc.name + '_end_points'\n",
        "    with slim.arg_scope([slim.convolution2d, slim.separable_convolution2d],\n",
        "                        activation_fn=None,\n",
        "                        outputs_collections=[end_points_collection]):\n",
        "      with slim.arg_scope([slim.batch_norm],\n",
        "                          is_training=is_training,\n",
        "                          activation_fn=tf.nn.relu):\n",
        "        net = slim.convolution2d(inputs, round(32 * width_multiplier), [3, 3], stride=2, padding='SAME', scope='conv_1')\n",
        "        net = slim.batch_norm(net, scope='conv_1/batch_norm')\n",
        "        net = _depthwise_separable_conv(net, 64, width_multiplier, sc='conv_ds_2')\n",
        "        net = _depthwise_separable_conv(net, 128, width_multiplier, downsample=True, sc='conv_ds_3')\n",
        "        net = _depthwise_separable_conv(net, 128, width_multiplier, sc='conv_ds_4')\n",
        "        net = _depthwise_separable_conv(net, 256, width_multiplier, downsample=True, sc='conv_ds_5')\n",
        "        net = _depthwise_separable_conv(net, 256, width_multiplier, sc='conv_ds_6')\n",
        "        net = _depthwise_separable_conv(net, 512, width_multiplier, downsample=True, sc='conv_ds_7')\n",
        "\n",
        "        net = _depthwise_separable_conv(net, 512, width_multiplier, sc='conv_ds_8')\n",
        "        net = _depthwise_separable_conv(net, 512, width_multiplier, sc='conv_ds_9')\n",
        "        net = _depthwise_separable_conv(net, 512, width_multiplier, sc='conv_ds_10')\n",
        "        net = _depthwise_separable_conv(net, 512, width_multiplier, sc='conv_ds_11')\n",
        "        net = _depthwise_separable_conv(net, 512, width_multiplier, sc='conv_ds_12')\n",
        "\n",
        "        net = _depthwise_separable_conv(net, 1024, width_multiplier, downsample=True, sc='conv_ds_13')\n",
        "        net = _depthwise_separable_conv(net, 1024, width_multiplier, sc='conv_ds_14')\n",
        "\n",
        "    end_points = slim.utils.convert_collection_to_dict(end_points_collection)\n",
        "\n",
        "  return end_points\n",
        "\n",
        "\n",
        "def mobilenet_arg_scope(weight_decay=0.0):\n",
        "  \"\"\"Defines the default mobilenet argument scope.\n",
        "  Args:\n",
        "    weight_decay: The weight decay to use for regularizing the model.\n",
        "  Returns:\n",
        "    An `arg_scope` to use for the MobileNet model.\n",
        "  \"\"\"\n",
        "  with slim.arg_scope(\n",
        "      [slim.convolution2d, slim.separable_convolution2d],\n",
        "      weights_initializer=slim.initializers.xavier_initializer(),\n",
        "      biases_initializer=slim.init_ops.zeros_initializer(),\n",
        "      weights_regularizer=slim.l2_regularizer(weight_decay)) as sc:\n",
        "    return sc"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}