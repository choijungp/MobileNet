{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\"\"\"Tests for slim.nets.resnet_v2.\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from nets import resnet_utils\n",
        "from nets import resnet_v2\n",
        "\n",
        "slim = tf.contrib.slim\n",
        "\n",
        "\n",
        "def create_test_input(batch_size, height, width, channels):\n",
        "  \"\"\"Create test input tensor.\n",
        "  Args:\n",
        "    batch_size: The number of images per batch or `None` if unknown.\n",
        "    height: The height of each image or `None` if unknown.\n",
        "    width: The width of each image or `None` if unknown.\n",
        "    channels: The number of channels per image or `None` if unknown.\n",
        "  Returns:\n",
        "    Either a placeholder `Tensor` of dimension\n",
        "      [batch_size, height, width, channels] if any of the inputs are `None` or a\n",
        "    constant `Tensor` with the mesh grid values along the spatial dimensions.\n",
        "  \"\"\"\n",
        "  if None in [batch_size, height, width, channels]:\n",
        "    return tf.placeholder(tf.float32, (batch_size, height, width, channels))\n",
        "  else:\n",
        "    return tf.to_float(\n",
        "        np.tile(\n",
        "            np.reshape(\n",
        "                np.reshape(np.arange(height), [height, 1]) +\n",
        "                np.reshape(np.arange(width), [1, width]),\n",
        "                [1, height, width, 1]),\n",
        "            [batch_size, 1, 1, channels]))\n",
        "\n",
        "\n",
        "class ResnetUtilsTest(tf.test.TestCase):\n",
        "\n",
        "  def testSubsampleThreeByThree(self):\n",
        "    x = tf.reshape(tf.to_float(tf.range(9)), [1, 3, 3, 1])\n",
        "    x = resnet_utils.subsample(x, 2)\n",
        "    expected = tf.reshape(tf.constant([0, 2, 6, 8]), [1, 2, 2, 1])\n",
        "    with self.test_session():\n",
        "      self.assertAllClose(x.eval(), expected.eval())\n",
        "\n",
        "  def testSubsampleFourByFour(self):\n",
        "    x = tf.reshape(tf.to_float(tf.range(16)), [1, 4, 4, 1])\n",
        "    x = resnet_utils.subsample(x, 2)\n",
        "    expected = tf.reshape(tf.constant([0, 2, 8, 10]), [1, 2, 2, 1])\n",
        "    with self.test_session():\n",
        "      self.assertAllClose(x.eval(), expected.eval())\n",
        "\n",
        "  def testConv2DSameEven(self):\n",
        "    n, n2 = 4, 2\n",
        "\n",
        "    # Input image.\n",
        "    x = create_test_input(1, n, n, 1)\n",
        "\n",
        "    # Convolution kernel.\n",
        "    w = create_test_input(1, 3, 3, 1)\n",
        "    w = tf.reshape(w, [3, 3, 1, 1])\n",
        "\n",
        "    tf.get_variable('Conv/weights', initializer=w)\n",
        "    tf.get_variable('Conv/biases', initializer=tf.zeros([1]))\n",
        "    tf.get_variable_scope().reuse_variables()\n",
        "\n",
        "    y1 = slim.conv2d(x, 1, [3, 3], stride=1, scope='Conv')\n",
        "    y1_expected = tf.to_float([[14, 28, 43, 26],\n",
        "                               [28, 48, 66, 37],\n",
        "                               [43, 66, 84, 46],\n",
        "                               [26, 37, 46, 22]])\n",
        "    y1_expected = tf.reshape(y1_expected, [1, n, n, 1])\n",
        "\n",
        "    y2 = resnet_utils.subsample(y1, 2)\n",
        "    y2_expected = tf.to_float([[14, 43],\n",
        "                               [43, 84]])\n",
        "    y2_expected = tf.reshape(y2_expected, [1, n2, n2, 1])\n",
        "\n",
        "    y3 = resnet_utils.conv2d_same(x, 1, 3, stride=2, scope='Conv')\n",
        "    y3_expected = y2_expected\n",
        "\n",
        "    y4 = slim.conv2d(x, 1, [3, 3], stride=2, scope='Conv')\n",
        "    y4_expected = tf.to_float([[48, 37],\n",
        "                               [37, 22]])\n",
        "    y4_expected = tf.reshape(y4_expected, [1, n2, n2, 1])\n",
        "\n",
        "    with self.test_session() as sess:\n",
        "      sess.run(tf.global_variables_initializer())\n",
        "      self.assertAllClose(y1.eval(), y1_expected.eval())\n",
        "      self.assertAllClose(y2.eval(), y2_expected.eval())\n",
        "      self.assertAllClose(y3.eval(), y3_expected.eval())\n",
        "      self.assertAllClose(y4.eval(), y4_expected.eval())\n",
        "\n",
        "  def testConv2DSameOdd(self):\n",
        "    n, n2 = 5, 3\n",
        "\n",
        "    # Input image.\n",
        "    x = create_test_input(1, n, n, 1)\n",
        "\n",
        "    # Convolution kernel.\n",
        "    w = create_test_input(1, 3, 3, 1)\n",
        "    w = tf.reshape(w, [3, 3, 1, 1])\n",
        "\n",
        "    tf.get_variable('Conv/weights', initializer=w)\n",
        "    tf.get_variable('Conv/biases', initializer=tf.zeros([1]))\n",
        "    tf.get_variable_scope().reuse_variables()\n",
        "\n",
        "    y1 = slim.conv2d(x, 1, [3, 3], stride=1, scope='Conv')\n",
        "    y1_expected = tf.to_float([[14, 28, 43, 58, 34],\n",
        "                               [28, 48, 66, 84, 46],\n",
        "                               [43, 66, 84, 102, 55],\n",
        "                               [58, 84, 102, 120, 64],\n",
        "                               [34, 46, 55, 64, 30]])\n",
        "    y1_expected = tf.reshape(y1_expected, [1, n, n, 1])\n",
        "\n",
        "    y2 = resnet_utils.subsample(y1, 2)\n",
        "    y2_expected = tf.to_float([[14, 43, 34],\n",
        "                               [43, 84, 55],\n",
        "                               [34, 55, 30]])\n",
        "    y2_expected = tf.reshape(y2_expected, [1, n2, n2, 1])\n",
        "\n",
        "    y3 = resnet_utils.conv2d_same(x, 1, 3, stride=2, scope='Conv')\n",
        "    y3_expected = y2_expected\n",
        "\n",
        "    y4 = slim.conv2d(x, 1, [3, 3], stride=2, scope='Conv')\n",
        "    y4_expected = y2_expected\n",
        "\n",
        "    with self.test_session() as sess:\n",
        "      sess.run(tf.global_variables_initializer())\n",
        "      self.assertAllClose(y1.eval(), y1_expected.eval())\n",
        "      self.assertAllClose(y2.eval(), y2_expected.eval())\n",
        "      self.assertAllClose(y3.eval(), y3_expected.eval())\n",
        "      self.assertAllClose(y4.eval(), y4_expected.eval())\n",
        "\n",
        "  def _resnet_plain(self, inputs, blocks, output_stride=None, scope=None):\n",
        "    \"\"\"A plain ResNet without extra layers before or after the ResNet blocks.\"\"\"\n",
        "    with tf.variable_scope(scope, values=[inputs]):\n",
        "      with slim.arg_scope([slim.conv2d], outputs_collections='end_points'):\n",
        "        net = resnet_utils.stack_blocks_dense(inputs, blocks, output_stride)\n",
        "        end_points = dict(tf.get_collection('end_points'))\n",
        "        return net, end_points\n",
        "\n",
        "  def testEndPointsV2(self):\n",
        "    \"\"\"Test the end points of a tiny v2 bottleneck network.\"\"\"\n",
        "    bottleneck = resnet_v2.bottleneck\n",
        "    blocks = [resnet_utils.Block('block1', bottleneck, [(4, 1, 1), (4, 1, 2)]),\n",
        "              resnet_utils.Block('block2', bottleneck, [(8, 2, 1), (8, 2, 1)])]\n",
        "    inputs = create_test_input(2, 32, 16, 3)\n",
        "    with slim.arg_scope(resnet_utils.resnet_arg_scope()):\n",
        "      _, end_points = self._resnet_plain(inputs, blocks, scope='tiny')\n",
        "    expected = [\n",
        "        'tiny/block1/unit_1/bottleneck_v2/shortcut',\n",
        "        'tiny/block1/unit_1/bottleneck_v2/conv1',\n",
        "        'tiny/block1/unit_1/bottleneck_v2/conv2',\n",
        "        'tiny/block1/unit_1/bottleneck_v2/conv3',\n",
        "        'tiny/block1/unit_2/bottleneck_v2/conv1',\n",
        "        'tiny/block1/unit_2/bottleneck_v2/conv2',\n",
        "        'tiny/block1/unit_2/bottleneck_v2/conv3',\n",
        "        'tiny/block2/unit_1/bottleneck_v2/shortcut',\n",
        "        'tiny/block2/unit_1/bottleneck_v2/conv1',\n",
        "        'tiny/block2/unit_1/bottleneck_v2/conv2',\n",
        "        'tiny/block2/unit_1/bottleneck_v2/conv3',\n",
        "        'tiny/block2/unit_2/bottleneck_v2/conv1',\n",
        "        'tiny/block2/unit_2/bottleneck_v2/conv2',\n",
        "        'tiny/block2/unit_2/bottleneck_v2/conv3']\n",
        "    self.assertItemsEqual(expected, end_points)\n",
        "\n",
        "  def _stack_blocks_nondense(self, net, blocks):\n",
        "    \"\"\"A simplified ResNet Block stacker without output stride control.\"\"\"\n",
        "    for block in blocks:\n",
        "      with tf.variable_scope(block.scope, 'block', [net]):\n",
        "        for i, unit in enumerate(block.args):\n",
        "          depth, depth_bottleneck, stride = unit\n",
        "          with tf.variable_scope('unit_%d' % (i + 1), values=[net]):\n",
        "            net = block.unit_fn(net,\n",
        "                                depth=depth,\n",
        "                                depth_bottleneck=depth_bottleneck,\n",
        "                                stride=stride,\n",
        "                                rate=1)\n",
        "    return net\n",
        "\n",
        "  def _atrousValues(self, bottleneck):\n",
        "    \"\"\"Verify the values of dense feature extraction by atrous convolution.\n",
        "    Make sure that dense feature extraction by stack_blocks_dense() followed by\n",
        "    subsampling gives identical results to feature extraction at the nominal\n",
        "    network output stride using the simple self._stack_blocks_nondense() above.\n",
        "    Args:\n",
        "      bottleneck: The bottleneck function.\n",
        "    \"\"\"\n",
        "    blocks = [\n",
        "        resnet_utils.Block('block1', bottleneck, [(4, 1, 1), (4, 1, 2)]),\n",
        "        resnet_utils.Block('block2', bottleneck, [(8, 2, 1), (8, 2, 2)]),\n",
        "        resnet_utils.Block('block3', bottleneck, [(16, 4, 1), (16, 4, 2)]),\n",
        "        resnet_utils.Block('block4', bottleneck, [(32, 8, 1), (32, 8, 1)])\n",
        "    ]\n",
        "    nominal_stride = 8\n",
        "\n",
        "    # Test both odd and even input dimensions.\n",
        "    height = 30\n",
        "    width = 31\n",
        "    with slim.arg_scope(resnet_utils.resnet_arg_scope()):\n",
        "      with slim.arg_scope([slim.batch_norm], is_training=False):\n",
        "        for output_stride in [1, 2, 4, 8, None]:\n",
        "          with tf.Graph().as_default():\n",
        "            with self.test_session() as sess:\n",
        "              tf.set_random_seed(0)\n",
        "              inputs = create_test_input(1, height, width, 3)\n",
        "              # Dense feature extraction followed by subsampling.\n",
        "              output = resnet_utils.stack_blocks_dense(inputs,\n",
        "                                                       blocks,\n",
        "                                                       output_stride)\n",
        "              if output_stride is None:\n",
        "                factor = 1\n",
        "              else:\n",
        "                factor = nominal_stride // output_stride\n",
        "\n",
        "              output = resnet_utils.subsample(output, factor)\n",
        "              # Make the two networks use the same weights.\n",
        "              tf.get_variable_scope().reuse_variables()\n",
        "              # Feature extraction at the nominal network rate.\n",
        "              expected = self._stack_blocks_nondense(inputs, blocks)\n",
        "              sess.run(tf.global_variables_initializer())\n",
        "              output, expected = sess.run([output, expected])\n",
        "              self.assertAllClose(output, expected, atol=1e-4, rtol=1e-4)\n",
        "\n",
        "  def testAtrousValuesBottleneck(self):\n",
        "    self._atrousValues(resnet_v2.bottleneck)\n",
        "\n",
        "\n",
        "class ResnetCompleteNetworkTest(tf.test.TestCase):\n",
        "  \"\"\"Tests with complete small ResNet v2 networks.\"\"\"\n",
        "\n",
        "  def _resnet_small(self,\n",
        "                    inputs,\n",
        "                    num_classes=None,\n",
        "                    is_training=True,\n",
        "                    global_pool=True,\n",
        "                    output_stride=None,\n",
        "                    include_root_block=True,\n",
        "                    reuse=None,\n",
        "                    scope='resnet_v2_small'):\n",
        "    \"\"\"A shallow and thin ResNet v2 for faster tests.\"\"\"\n",
        "    bottleneck = resnet_v2.bottleneck\n",
        "    blocks = [\n",
        "        resnet_utils.Block(\n",
        "            'block1', bottleneck, [(4, 1, 1)] * 2 + [(4, 1, 2)]),\n",
        "        resnet_utils.Block(\n",
        "            'block2', bottleneck, [(8, 2, 1)] * 2 + [(8, 2, 2)]),\n",
        "        resnet_utils.Block(\n",
        "            'block3', bottleneck, [(16, 4, 1)] * 2 + [(16, 4, 2)]),\n",
        "        resnet_utils.Block(\n",
        "            'block4', bottleneck, [(32, 8, 1)] * 2)]\n",
        "    return resnet_v2.resnet_v2(inputs, blocks, num_classes,\n",
        "                               is_training=is_training,\n",
        "                               global_pool=global_pool,\n",
        "                               output_stride=output_stride,\n",
        "                               include_root_block=include_root_block,\n",
        "                               reuse=reuse,\n",
        "                               scope=scope)\n",
        "\n",
        "  def testClassificationEndPoints(self):\n",
        "    global_pool = True\n",
        "    num_classes = 10\n",
        "    inputs = create_test_input(2, 224, 224, 3)\n",
        "    with slim.arg_scope(resnet_utils.resnet_arg_scope()):\n",
        "      logits, end_points = self._resnet_small(inputs, num_classes,\n",
        "                                              global_pool=global_pool,\n",
        "                                              scope='resnet')\n",
        "    self.assertTrue(logits.op.name.startswith('resnet/logits'))\n",
        "    self.assertListEqual(logits.get_shape().as_list(), [2, 1, 1, num_classes])\n",
        "    self.assertTrue('predictions' in end_points)\n",
        "    self.assertListEqual(end_points['predictions'].get_shape().as_list(),\n",
        "                         [2, 1, 1, num_classes])\n",
        "\n",
        "  def testClassificationShapes(self):\n",
        "    global_pool = True\n",
        "    num_classes = 10\n",
        "    inputs = create_test_input(2, 224, 224, 3)\n",
        "    with slim.arg_scope(resnet_utils.resnet_arg_scope()):\n",
        "      _, end_points = self._resnet_small(inputs, num_classes,\n",
        "                                         global_pool=global_pool,\n",
        "                                         scope='resnet')\n",
        "      endpoint_to_shape = {\n",
        "          'resnet/block1': [2, 28, 28, 4],\n",
        "          'resnet/block2': [2, 14, 14, 8],\n",
        "          'resnet/block3': [2, 7, 7, 16],\n",
        "          'resnet/block4': [2, 7, 7, 32]}\n",
        "      for endpoint in endpoint_to_shape:\n",
        "        shape = endpoint_to_shape[endpoint]\n",
        "        self.assertListEqual(end_points[endpoint].get_shape().as_list(), shape)\n",
        "\n",
        "  def testFullyConvolutionalEndpointShapes(self):\n",
        "    global_pool = False\n",
        "    num_classes = 10\n",
        "    inputs = create_test_input(2, 321, 321, 3)\n",
        "    with slim.arg_scope(resnet_utils.resnet_arg_scope()):\n",
        "      _, end_points = self._resnet_small(inputs, num_classes,\n",
        "                                         global_pool=global_pool,\n",
        "                                         scope='resnet')\n",
        "      endpoint_to_shape = {\n",
        "          'resnet/block1': [2, 41, 41, 4],\n",
        "          'resnet/block2': [2, 21, 21, 8],\n",
        "          'resnet/block3': [2, 11, 11, 16],\n",
        "          'resnet/block4': [2, 11, 11, 32]}\n",
        "      for endpoint in endpoint_to_shape:\n",
        "        shape = endpoint_to_shape[endpoint]\n",
        "        self.assertListEqual(end_points[endpoint].get_shape().as_list(), shape)\n",
        "\n",
        "  def testRootlessFullyConvolutionalEndpointShapes(self):\n",
        "    global_pool = False\n",
        "    num_classes = 10\n",
        "    inputs = create_test_input(2, 128, 128, 3)\n",
        "    with slim.arg_scope(resnet_utils.resnet_arg_scope()):\n",
        "      _, end_points = self._resnet_small(inputs, num_classes,\n",
        "                                         global_pool=global_pool,\n",
        "                                         include_root_block=False,\n",
        "                                         scope='resnet')\n",
        "      endpoint_to_shape = {\n",
        "          'resnet/block1': [2, 64, 64, 4],\n",
        "          'resnet/block2': [2, 32, 32, 8],\n",
        "          'resnet/block3': [2, 16, 16, 16],\n",
        "          'resnet/block4': [2, 16, 16, 32]}\n",
        "      for endpoint in endpoint_to_shape:\n",
        "        shape = endpoint_to_shape[endpoint]\n",
        "        self.assertListEqual(end_points[endpoint].get_shape().as_list(), shape)\n",
        "\n",
        "  def testAtrousFullyConvolutionalEndpointShapes(self):\n",
        "    global_pool = False\n",
        "    num_classes = 10\n",
        "    output_stride = 8\n",
        "    inputs = create_test_input(2, 321, 321, 3)\n",
        "    with slim.arg_scope(resnet_utils.resnet_arg_scope()):\n",
        "      _, end_points = self._resnet_small(inputs,\n",
        "                                         num_classes,\n",
        "                                         global_pool=global_pool,\n",
        "                                         output_stride=output_stride,\n",
        "                                         scope='resnet')\n",
        "      endpoint_to_shape = {\n",
        "          'resnet/block1': [2, 41, 41, 4],\n",
        "          'resnet/block2': [2, 41, 41, 8],\n",
        "          'resnet/block3': [2, 41, 41, 16],\n",
        "          'resnet/block4': [2, 41, 41, 32]}\n",
        "      for endpoint in endpoint_to_shape:\n",
        "        shape = endpoint_to_shape[endpoint]\n",
        "        self.assertListEqual(end_points[endpoint].get_shape().as_list(), shape)\n",
        "\n",
        "  def testAtrousFullyConvolutionalValues(self):\n",
        "    \"\"\"Verify dense feature extraction with atrous convolution.\"\"\"\n",
        "    nominal_stride = 32\n",
        "    for output_stride in [4, 8, 16, 32, None]:\n",
        "      with slim.arg_scope(resnet_utils.resnet_arg_scope()):\n",
        "        with tf.Graph().as_default():\n",
        "          with self.test_session() as sess:\n",
        "            tf.set_random_seed(0)\n",
        "            inputs = create_test_input(2, 81, 81, 3)\n",
        "            # Dense feature extraction followed by subsampling.\n",
        "            output, _ = self._resnet_small(inputs, None,\n",
        "                                           is_training=False,\n",
        "                                           global_pool=False,\n",
        "                                           output_stride=output_stride)\n",
        "            if output_stride is None:\n",
        "              factor = 1\n",
        "            else:\n",
        "              factor = nominal_stride // output_stride\n",
        "            output = resnet_utils.subsample(output, factor)\n",
        "            # Make the two networks use the same weights.\n",
        "            tf.get_variable_scope().reuse_variables()\n",
        "            # Feature extraction at the nominal network rate.\n",
        "            expected, _ = self._resnet_small(inputs, None,\n",
        "                                             is_training=False,\n",
        "                                             global_pool=False)\n",
        "            sess.run(tf.global_variables_initializer())\n",
        "            self.assertAllClose(output.eval(), expected.eval(),\n",
        "                                atol=1e-4, rtol=1e-4)\n",
        "\n",
        "  def testUnknownBatchSize(self):\n",
        "    batch = 2\n",
        "    height, width = 65, 65\n",
        "    global_pool = True\n",
        "    num_classes = 10\n",
        "    inputs = create_test_input(None, height, width, 3)\n",
        "    with slim.arg_scope(resnet_utils.resnet_arg_scope()):\n",
        "      logits, _ = self._resnet_small(inputs, num_classes,\n",
        "                                     global_pool=global_pool,\n",
        "                                     scope='resnet')\n",
        "    self.assertTrue(logits.op.name.startswith('resnet/logits'))\n",
        "    self.assertListEqual(logits.get_shape().as_list(),\n",
        "                         [None, 1, 1, num_classes])\n",
        "    images = create_test_input(batch, height, width, 3)\n",
        "    with self.test_session() as sess:\n",
        "      sess.run(tf.global_variables_initializer())\n",
        "      output = sess.run(logits, {inputs: images.eval()})\n",
        "      self.assertEqual(output.shape, (batch, 1, 1, num_classes))\n",
        "\n",
        "  def testFullyConvolutionalUnknownHeightWidth(self):\n",
        "    batch = 2\n",
        "    height, width = 65, 65\n",
        "    global_pool = False\n",
        "    inputs = create_test_input(batch, None, None, 3)\n",
        "    with slim.arg_scope(resnet_utils.resnet_arg_scope()):\n",
        "      output, _ = self._resnet_small(inputs, None,\n",
        "                                     global_pool=global_pool)\n",
        "    self.assertListEqual(output.get_shape().as_list(),\n",
        "                         [batch, None, None, 32])\n",
        "    images = create_test_input(batch, height, width, 3)\n",
        "    with self.test_session() as sess:\n",
        "      sess.run(tf.global_variables_initializer())\n",
        "      output = sess.run(output, {inputs: images.eval()})\n",
        "      self.assertEqual(output.shape, (batch, 3, 3, 32))\n",
        "\n",
        "  def testAtrousFullyConvolutionalUnknownHeightWidth(self):\n",
        "    batch = 2\n",
        "    height, width = 65, 65\n",
        "    global_pool = False\n",
        "    output_stride = 8\n",
        "    inputs = create_test_input(batch, None, None, 3)\n",
        "    with slim.arg_scope(resnet_utils.resnet_arg_scope()):\n",
        "      output, _ = self._resnet_small(inputs,\n",
        "                                     None,\n",
        "                                     global_pool=global_pool,\n",
        "                                     output_stride=output_stride)\n",
        "    self.assertListEqual(output.get_shape().as_list(),\n",
        "                         [batch, None, None, 32])\n",
        "    images = create_test_input(batch, height, width, 3)\n",
        "    with self.test_session() as sess:\n",
        "      sess.run(tf.global_variables_initializer())\n",
        "      output = sess.run(output, {inputs: images.eval()})\n",
        "      self.assertEqual(output.shape, (batch, 9, 9, 32))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  tf.test.main()"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}