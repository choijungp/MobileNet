{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import tensorflow as tf\n",
        "import time\n",
        "from datetime import datetime\n",
        "import math\n",
        "import argparse\n",
        "import sys\n",
        "from nets.mobilenet import mobilenet, mobilenet_arg_scope\n",
        "import numpy as np\n",
        "\n",
        "slim = tf.contrib.slim\n",
        "\n",
        "\n",
        "def time_tensorflow_run(session, target, info_string):\n",
        "  num_steps_burn_in = 10\n",
        "  total_duration = 0.0\n",
        "  total_duration_squared = 0.0\n",
        "\n",
        "  for i in range(FLAGS.num_batches + num_steps_burn_in):\n",
        "    start_time = time.time()\n",
        "    _ = session.run(target)\n",
        "    duration = time.time() - start_time\n",
        "    if i >= num_steps_burn_in:\n",
        "      if not i % 10:\n",
        "        print('%s: step %d, duration = %.3f' % (datetime.now(), i - num_steps_burn_in, duration))\n",
        "      total_duration += duration\n",
        "      total_duration_squared += duration * duration\n",
        "\n",
        "  mn = total_duration / FLAGS.num_batches\n",
        "  vr = total_duration_squared / FLAGS.num_batches - mn * mn\n",
        "  sd = math.sqrt(vr)\n",
        "  print('%s: %s across %d steps, %.3f +/- %.3f sec / batch' % (datetime.now(), info_string, FLAGS.num_batches, mn, sd))\n",
        "\n",
        "def time_tensorflow_run_placeholder(session, target, feed_dict, info_string):\n",
        "  num_steps_burn_in = 10\n",
        "  total_duration = 0.0\n",
        "  total_duration_squared = 0.0\n",
        "\n",
        "  for i in range(FLAGS.num_batches + num_steps_burn_in):\n",
        "    start_time = time.time()\n",
        "    _ = session.run(target,feed_dict=feed_dict)\n",
        "    duration = time.time() - start_time\n",
        "    if i >= num_steps_burn_in:\n",
        "      if not i % 10:\n",
        "        print('%s: step %d, duration = %.3f' % (datetime.now(), i - num_steps_burn_in, duration))\n",
        "      total_duration += duration\n",
        "      total_duration_squared += duration * duration\n",
        "\n",
        "  mn = total_duration / FLAGS.num_batches\n",
        "  vr = total_duration_squared / FLAGS.num_batches - mn * mn\n",
        "  sd = math.sqrt(vr)\n",
        "  print('%s: %s across %d steps, %.3f +/- %.3f sec / batch' % (datetime.now(), info_string, FLAGS.num_batches, mn, sd))\n",
        "\n",
        "def run_benchmark():\n",
        "  if FLAGS.quantized:\n",
        "    graph_filename = FLAGS.quantized_graph\n",
        "    # Create a graph def object to read the graph\n",
        "    with tf.gfile.GFile(graph_filename, \"rb\") as f:\n",
        "      graph_def = tf.GraphDef()\n",
        "      graph_def.ParseFromString(f.read())\n",
        "\n",
        "  with tf.Graph().as_default() as graph:\n",
        "    with tf.device('/'+FLAGS.mode+':0'):\n",
        "      image_size = 224\n",
        "      if FLAGS.quantized:\n",
        "        inputs = np.random.random((FLAGS.batch_size, image_size, image_size, 3))\n",
        "        tf.import_graph_def(graph_def)\n",
        "        config = tf.ConfigProto()\n",
        "        config.gpu_options.allocator_type = 'BFC'\n",
        "        sess = tf.Session(config=config)\n",
        "        # We define the input and output node we will feed in\n",
        "        input_node = graph.get_tensor_by_name('import/MobileNet/input_images:0')\n",
        "        output_node = graph.get_tensor_by_name('import/MobileNet/Predictions/Softmax:0')\n",
        "        time_tensorflow_run_placeholder(sess, output_node, {input_node: inputs}, \"Forward\")\n",
        "      else:\n",
        "        image_size = 224\n",
        "        inputs = tf.Variable(tf.random_normal([FLAGS.batch_size,\n",
        "                                               image_size,\n",
        "                                               image_size, 3],\n",
        "                                              dtype=tf.float32,\n",
        "                                              stddev=1e-1))\n",
        "        with slim.arg_scope(mobilenet_arg_scope()):\n",
        "          logits, end_points = mobilenet(inputs, is_training=False)\n",
        "\n",
        "        init = tf.global_variables_initializer()\n",
        "        config = tf.ConfigProto()\n",
        "        config.gpu_options.allocator_type = 'BFC'\n",
        "        sess = tf.Session(config=config)\n",
        "        sess.run(init)\n",
        "\n",
        "        time_tensorflow_run(sess, logits, \"Forward\")\n",
        "\n",
        "        # Add a simple objective so we can calculate the backward pass.\n",
        "        objective = tf.nn.l2_loss(logits)\n",
        "\n",
        "        # Compute the gradient with respect to all the parameters.\n",
        "        grad = tf.gradients(objective, tf.trainable_variables())\n",
        "\n",
        "        # Run the backward benchmark.\n",
        "        time_tensorflow_run(sess, grad, \"Forward-backward\")\n",
        "\n",
        "def main(_):\n",
        "  run_benchmark()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  parser = argparse.ArgumentParser()\n",
        "  parser.add_argument(\n",
        "    '--batch_size',\n",
        "    type=int,\n",
        "    default=1,\n",
        "    help='Batch size.'\n",
        "  )\n",
        "  parser.add_argument(\n",
        "    '--num_batches',\n",
        "    type=int,\n",
        "    default=100,\n",
        "    help='Number of batches to run.'\n",
        "  )\n",
        "  parser.add_argument(\n",
        "    '--mode',\n",
        "    type=str,\n",
        "    default='cpu',\n",
        "    help='gpu/cpu mode.'\n",
        "  )\n",
        "  parser.add_argument(\n",
        "    '--quantized',\n",
        "    type=bool,\n",
        "    default=False,\n",
        "    help='Benchmark quantized graph.'\n",
        "  )\n",
        "  parser.add_argument(\n",
        "    '--quantized_graph',\n",
        "    type=str,\n",
        "    default='',\n",
        "    help='Path to quantized graph file.'\n",
        "  )\n",
        "  FLAGS, unparsed = parser.parse_known_args()\n",
        "  tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}