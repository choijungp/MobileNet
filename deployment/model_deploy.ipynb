{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\"\"\"Deploy Slim models across multiple clones and replicas.\n",
        "# TODO(sguada) docstring paragraph by (a) motivating the need for the file and\n",
        "# (b) defining clones.\n",
        "# TODO(sguada) describe the high-level components of model deployment.\n",
        "# E.g. \"each model deployment is composed of several parts: a DeploymentConfig,\n",
        "# which captures A, B and C, an input_fn which loads data.. etc\n",
        "To easily train a model on multiple GPUs or across multiple machines this\n",
        "module provides a set of helper functions: `create_clones`,\n",
        "`optimize_clones` and `deploy`.\n",
        "Usage:\n",
        "  g = tf.Graph()\n",
        "  # Set up DeploymentConfig\n",
        "  config = model_deploy.DeploymentConfig(num_clones=2, clone_on_cpu=True)\n",
        "  # Create the global step on the device storing the variables.\n",
        "  with tf.device(config.variables_device()):\n",
        "    global_step = slim.create_global_step()\n",
        "  # Define the inputs\n",
        "  with tf.device(config.inputs_device()):\n",
        "    images, labels = LoadData(...)\n",
        "    inputs_queue = slim.data.prefetch_queue((images, labels))\n",
        "  # Define the optimizer.\n",
        "  with tf.device(config.optimizer_device()):\n",
        "    optimizer = tf.train.MomentumOptimizer(FLAGS.learning_rate, FLAGS.momentum)\n",
        "  # Define the model including the loss.\n",
        "  def model_fn(inputs_queue):\n",
        "    images, labels = inputs_queue.dequeue()\n",
        "    predictions = CreateNetwork(images)\n",
        "    slim.losses.log_loss(predictions, labels)\n",
        "  model_dp = model_deploy.deploy(config, model_fn, [inputs_queue],\n",
        "                                 optimizer=optimizer)\n",
        "  # Run training.\n",
        "  slim.learning.train(model_dp.train_op, my_log_dir,\n",
        "                      summary_op=model_dp.summary_op)\n",
        "The Clone namedtuple holds together the values associated with each call to\n",
        "model_fn:\n",
        "  * outputs: The return values of the calls to `model_fn()`.\n",
        "  * scope: The scope used to create the clone.\n",
        "  * device: The device used to create the clone.\n",
        "DeployedModel namedtuple, holds together the values needed to train multiple\n",
        "clones:\n",
        "  * train_op: An operation that run the optimizer training op and include\n",
        "    all the update ops created by `model_fn`. Present only if an optimizer\n",
        "    was specified.\n",
        "  * summary_op: An operation that run the summaries created by `model_fn`\n",
        "    and process_gradients.\n",
        "  * total_loss: A `Tensor` that contains the sum of all losses created by\n",
        "    `model_fn` plus the regularization losses.\n",
        "  * clones: List of `Clone` tuples returned by `create_clones()`.\n",
        "DeploymentConfig parameters:\n",
        "  * num_clones: Number of model clones to deploy in each replica.\n",
        "  * clone_on_cpu: True if clones should be placed on CPU.\n",
        "  * replica_id: Integer.  Index of the replica for which the model is\n",
        "      deployed.  Usually 0 for the chief replica.\n",
        "  * num_replicas: Number of replicas to use.\n",
        "  * num_ps_tasks: Number of tasks for the `ps` job. 0 to not use replicas.\n",
        "  * worker_job_name: A name for the worker job.\n",
        "  * ps_job_name: A name for the parameter server job.\n",
        "TODO(sguada):\n",
        "  - describe side effect to the graph.\n",
        "  - what happens to summaries and update_ops.\n",
        "  - which graph collections are altered.\n",
        "  - write a tutorial on how to use this.\n",
        "  - analyze the possibility of calling deploy more than once.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import collections\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.python.ops import control_flow_ops\n",
        "\n",
        "slim = tf.contrib.slim\n",
        "\n",
        "\n",
        "__all__ = ['create_clones',\n",
        "           'deploy',\n",
        "           'optimize_clones',\n",
        "           'DeployedModel',\n",
        "           'DeploymentConfig',\n",
        "           'Clone',\n",
        "          ]\n",
        "\n",
        "\n",
        "# Namedtuple used to represent a clone during deployment.\n",
        "Clone = collections.namedtuple('Clone',\n",
        "                               ['outputs',  # Whatever model_fn() returned.\n",
        "                                'scope',  # The scope used to create it.\n",
        "                                'device',  # The device used to create.\n",
        "                               ])\n",
        "\n",
        "# Namedtuple used to represent a DeployedModel, returned by deploy().\n",
        "DeployedModel = collections.namedtuple('DeployedModel',\n",
        "                                       ['train_op',  # The `train_op`\n",
        "                                        'summary_op',  # The `summary_op`\n",
        "                                        'total_loss',  # The loss `Tensor`\n",
        "                                        'clones',  # A list of `Clones` tuples.\n",
        "                                       ])\n",
        "\n",
        "# Default parameters for DeploymentConfig\n",
        "_deployment_params = {'num_clones': 1,\n",
        "                      'clone_on_cpu': False,\n",
        "                      'replica_id': 0,\n",
        "                      'num_replicas': 1,\n",
        "                      'num_ps_tasks': 0,\n",
        "                      'worker_job_name': 'worker',\n",
        "                      'ps_job_name': 'ps'}\n",
        "\n",
        "\n",
        "def create_clones(config, model_fn, args=None, kwargs=None):\n",
        "  \"\"\"Creates multiple clones according to config using a `model_fn`.\n",
        "  The returned values of `model_fn(*args, **kwargs)` are collected along with\n",
        "  the scope and device used to created it in a namedtuple\n",
        "  `Clone(outputs, scope, device)`\n",
        "  Note: it is assumed that any loss created by `model_fn` is collected at\n",
        "  the tf.GraphKeys.LOSSES collection.\n",
        "  To recover the losses, summaries or update_ops created by the clone use:\n",
        "  ```python\n",
        "    losses = tf.get_collection(tf.GraphKeys.LOSSES, clone.scope)\n",
        "    summaries = tf.get_collection(tf.GraphKeys.SUMMARIES, clone.scope)\n",
        "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS, clone.scope)\n",
        "  ```\n",
        "  The deployment options are specified by the config object and support\n",
        "  deploying one or several clones on different GPUs and one or several replicas\n",
        "  of such clones.\n",
        "  The argument `model_fn` is called `config.num_clones` times to create the\n",
        "  model clones as `model_fn(*args, **kwargs)`.\n",
        "  If `config` specifies deployment on multiple replicas then the default\n",
        "  tensorflow device is set appropriatly for each call to `model_fn` and for the\n",
        "  slim variable creation functions: model and global variables will be created\n",
        "  on the `ps` device, the clone operations will be on the `worker` device.\n",
        "  Args:\n",
        "    config: A DeploymentConfig object.\n",
        "    model_fn: A callable. Called as `model_fn(*args, **kwargs)`\n",
        "    args: Optional list of arguments to pass to `model_fn`.\n",
        "    kwargs: Optional list of keyword arguments to pass to `model_fn`.\n",
        "  Returns:\n",
        "    A list of namedtuples `Clone`.\n",
        "  \"\"\"\n",
        "  clones = []\n",
        "  args = args or []\n",
        "  kwargs = kwargs or {}\n",
        "  with slim.arg_scope([slim.model_variable, slim.variable],\n",
        "                      device=config.variables_device()):\n",
        "    # Create clones.\n",
        "    for i in range(0, config.num_clones):\n",
        "      with tf.name_scope(config.clone_scope(i)) as clone_scope:\n",
        "        clone_device = config.clone_device(i)\n",
        "        with tf.device(clone_device):\n",
        "          with tf.variable_scope(tf.get_variable_scope(),\n",
        "                                 reuse=True if i > 0 else None):\n",
        "            outputs = model_fn(*args, **kwargs)\n",
        "          clones.append(Clone(outputs, clone_scope, clone_device))\n",
        "  return clones\n",
        "\n",
        "\n",
        "def _gather_clone_loss(clone, num_clones, regularization_losses):\n",
        "  \"\"\"Gather the loss for a single clone.\n",
        "  Args:\n",
        "    clone: A Clone namedtuple.\n",
        "    num_clones: The number of clones being deployed.\n",
        "    regularization_losses: Possibly empty list of regularization_losses\n",
        "      to add to the clone losses.\n",
        "  Returns:\n",
        "    A tensor for the total loss for the clone.  Can be None.\n",
        "  \"\"\"\n",
        "  # The return value.\n",
        "  sum_loss = None\n",
        "  # Individual components of the loss that will need summaries.\n",
        "  clone_loss = None\n",
        "  regularization_loss = None\n",
        "  # Compute and aggregate losses on the clone device.\n",
        "  with tf.device(clone.device):\n",
        "    all_losses = []\n",
        "    clone_losses = tf.get_collection(tf.GraphKeys.LOSSES, clone.scope)\n",
        "    if clone_losses:\n",
        "      clone_loss = tf.add_n(clone_losses, name='clone_loss')\n",
        "      if num_clones > 1:\n",
        "        clone_loss = tf.div(clone_loss, 1.0 * num_clones,\n",
        "                            name='scaled_clone_loss')\n",
        "      all_losses.append(clone_loss)\n",
        "    if regularization_losses:\n",
        "      regularization_loss = tf.add_n(regularization_losses,\n",
        "                                     name='regularization_loss')\n",
        "      all_losses.append(regularization_loss)\n",
        "    if all_losses:\n",
        "      sum_loss = tf.add_n(all_losses)\n",
        "  # Add the summaries out of the clone device block.\n",
        "  if clone_loss is not None:\n",
        "    tf.summary.scalar(clone.scope + '/clone_loss', clone_loss)\n",
        "  if regularization_loss is not None:\n",
        "    tf.summary.scalar('regularization_loss', regularization_loss)\n",
        "  return sum_loss\n",
        "\n",
        "\n",
        "def _optimize_clone(optimizer, clone, num_clones, regularization_losses,\n",
        "                    **kwargs):\n",
        "  \"\"\"Compute losses and gradients for a single clone.\n",
        "  Args:\n",
        "    optimizer: A tf.Optimizer  object.\n",
        "    clone: A Clone namedtuple.\n",
        "    num_clones: The number of clones being deployed.\n",
        "    regularization_losses: Possibly empty list of regularization_losses\n",
        "      to add to the clone losses.\n",
        "    **kwargs: Dict of kwarg to pass to compute_gradients().\n",
        "  Returns:\n",
        "    A tuple (clone_loss, clone_grads_and_vars).\n",
        "      - clone_loss: A tensor for the total loss for the clone.  Can be None.\n",
        "      - clone_grads_and_vars: List of (gradient, variable) for the clone.\n",
        "        Can be empty.\n",
        "  \"\"\"\n",
        "  sum_loss = _gather_clone_loss(clone, num_clones, regularization_losses)\n",
        "  clone_grad = None\n",
        "  if sum_loss is not None:\n",
        "    with tf.device(clone.device):\n",
        "      clone_grad = optimizer.compute_gradients(sum_loss, **kwargs)\n",
        "  return sum_loss, clone_grad\n",
        "\n",
        "\n",
        "def optimize_clones(clones, optimizer,\n",
        "                    regularization_losses=None,\n",
        "                    **kwargs):\n",
        "  \"\"\"Compute clone losses and gradients for the given list of `Clones`.\n",
        "  Note: The regularization_losses are added to the first clone losses.\n",
        "  Args:\n",
        "   clones: List of `Clones` created by `create_clones()`.\n",
        "   optimizer: An `Optimizer` object.\n",
        "   regularization_losses: Optional list of regularization losses. If None it\n",
        "     will gather them from tf.GraphKeys.REGULARIZATION_LOSSES. Pass `[]` to\n",
        "     exclude them.\n",
        "   **kwargs: Optional list of keyword arguments to pass to `compute_gradients`.\n",
        "  Returns:\n",
        "   A tuple (total_loss, grads_and_vars).\n",
        "     - total_loss: A Tensor containing the average of the clone losses including\n",
        "       the regularization loss.\n",
        "     - grads_and_vars: A List of tuples (gradient, variable) containing the sum\n",
        "       of the gradients for each variable.\n",
        "  \"\"\"\n",
        "  grads_and_vars = []\n",
        "  clones_losses = []\n",
        "  num_clones = len(clones)\n",
        "  if regularization_losses is None:\n",
        "    regularization_losses = tf.get_collection(\n",
        "        tf.GraphKeys.REGULARIZATION_LOSSES)\n",
        "  for clone in clones:\n",
        "    with tf.name_scope(clone.scope):\n",
        "      clone_loss, clone_grad = _optimize_clone(\n",
        "          optimizer, clone, num_clones, regularization_losses, **kwargs)\n",
        "      if clone_loss is not None:\n",
        "        clones_losses.append(clone_loss)\n",
        "        grads_and_vars.append(clone_grad)\n",
        "      # Only use regularization_losses for the first clone\n",
        "      regularization_losses = None\n",
        "  # Compute the total_loss summing all the clones_losses.\n",
        "  total_loss = tf.add_n(clones_losses, name='total_loss')\n",
        "  # Sum the gradients across clones.\n",
        "  grads_and_vars = _sum_clones_gradients(grads_and_vars)\n",
        "  return total_loss, grads_and_vars\n",
        "\n",
        "\n",
        "def deploy(config,\n",
        "           model_fn,\n",
        "           args=None,\n",
        "           kwargs=None,\n",
        "           optimizer=None,\n",
        "           summarize_gradients=False):\n",
        "  \"\"\"Deploys a Slim-constructed model across multiple clones.\n",
        "  The deployment options are specified by the config object and support\n",
        "  deploying one or several clones on different GPUs and one or several replicas\n",
        "  of such clones.\n",
        "  The argument `model_fn` is called `config.num_clones` times to create the\n",
        "  model clones as `model_fn(*args, **kwargs)`.\n",
        "  The optional argument `optimizer` is an `Optimizer` object.  If not `None`,\n",
        "  the deployed model is configured for training with that optimizer.\n",
        "  If `config` specifies deployment on multiple replicas then the default\n",
        "  tensorflow device is set appropriatly for each call to `model_fn` and for the\n",
        "  slim variable creation functions: model and global variables will be created\n",
        "  on the `ps` device, the clone operations will be on the `worker` device.\n",
        "  Args:\n",
        "    config: A `DeploymentConfig` object.\n",
        "    model_fn: A callable. Called as `model_fn(*args, **kwargs)`\n",
        "    args: Optional list of arguments to pass to `model_fn`.\n",
        "    kwargs: Optional list of keyword arguments to pass to `model_fn`.\n",
        "    optimizer: Optional `Optimizer` object.  If passed the model is deployed\n",
        "      for training with that optimizer.\n",
        "    summarize_gradients: Whether or not add summaries to the gradients.\n",
        "  Returns:\n",
        "    A `DeployedModel` namedtuple.\n",
        "  \"\"\"\n",
        "  # Gather initial summaries.\n",
        "  summaries = set(tf.get_collection(tf.GraphKeys.SUMMARIES))\n",
        "\n",
        "  # Create Clones.\n",
        "  clones = create_clones(config, model_fn, args, kwargs)\n",
        "  first_clone = clones[0]\n",
        "\n",
        "  # Gather update_ops from the first clone. These contain, for example,\n",
        "  # the updates for the batch_norm variables created by model_fn.\n",
        "  update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS, first_clone.scope)\n",
        "\n",
        "  train_op = None\n",
        "  total_loss = None\n",
        "  with tf.device(config.optimizer_device()):\n",
        "    if optimizer:\n",
        "      # Place the global step on the device storing the variables.\n",
        "      with tf.device(config.variables_device()):\n",
        "        global_step = slim.get_or_create_global_step()\n",
        "\n",
        "      # Compute the gradients for the clones.\n",
        "      total_loss, clones_gradients = optimize_clones(clones, optimizer)\n",
        "\n",
        "      if clones_gradients:\n",
        "        if summarize_gradients:\n",
        "          # Add summaries to the gradients.\n",
        "          summaries |= set(_add_gradients_summaries(clones_gradients))\n",
        "\n",
        "        # Create gradient updates.\n",
        "        grad_updates = optimizer.apply_gradients(clones_gradients,\n",
        "                                                 global_step=global_step)\n",
        "        update_ops.append(grad_updates)\n",
        "\n",
        "        update_op = tf.group(*update_ops)\n",
        "        train_op = control_flow_ops.with_dependencies([update_op], total_loss,\n",
        "                                                      name='train_op')\n",
        "    else:\n",
        "      clones_losses = []\n",
        "      regularization_losses = tf.get_collection(\n",
        "          tf.GraphKeys.REGULARIZATION_LOSSES)\n",
        "      for clone in clones:\n",
        "        with tf.name_scope(clone.scope):\n",
        "          clone_loss = _gather_clone_loss(clone, len(clones),\n",
        "                                          regularization_losses)\n",
        "          if clone_loss is not None:\n",
        "            clones_losses.append(clone_loss)\n",
        "          # Only use regularization_losses for the first clone\n",
        "          regularization_losses = None\n",
        "      if clones_losses:\n",
        "        total_loss = tf.add_n(clones_losses, name='total_loss')\n",
        "\n",
        "    # Add the summaries from the first clone. These contain the summaries\n",
        "    # created by model_fn and either optimize_clones() or _gather_clone_loss().\n",
        "    summaries |= set(tf.get_collection(tf.GraphKeys.SUMMARIES,\n",
        "                                       first_clone.scope))\n",
        "\n",
        "    if total_loss is not None:\n",
        "      # Add total_loss to summary.\n",
        "      summaries.add(tf.summary.scalar('total_loss', total_loss))\n",
        "\n",
        "    if summaries:\n",
        "      # Merge all summaries together.\n",
        "      summary_op = tf.summary.merge(list(summaries), name='summary_op')\n",
        "    else:\n",
        "      summary_op = None\n",
        "\n",
        "  return DeployedModel(train_op, summary_op, total_loss, clones)\n",
        "\n",
        "\n",
        "def _sum_clones_gradients(clone_grads):\n",
        "  \"\"\"Calculate the sum gradient for each shared variable across all clones.\n",
        "  This function assumes that the clone_grads has been scaled appropriately by\n",
        "  1 / num_clones.\n",
        "  Args:\n",
        "    clone_grads: A List of List of tuples (gradient, variable), one list per\n",
        "    `Clone`.\n",
        "  Returns:\n",
        "     List of tuples of (gradient, variable) where the gradient has been summed\n",
        "     across all clones.\n",
        "  \"\"\"\n",
        "  sum_grads = []\n",
        "  for grad_and_vars in zip(*clone_grads):\n",
        "    # Note that each grad_and_vars looks like the following:\n",
        "    #   ((grad_var0_clone0, var0), ... (grad_varN_cloneN, varN))\n",
        "    grads = []\n",
        "    var = grad_and_vars[0][1]\n",
        "    for g, v in grad_and_vars:\n",
        "      assert v == var\n",
        "      if g is not None:\n",
        "        grads.append(g)\n",
        "    if grads:\n",
        "      if len(grads) > 1:\n",
        "        sum_grad = tf.add_n(grads, name=var.op.name + '/sum_grads')\n",
        "      else:\n",
        "        sum_grad = grads[0]\n",
        "      sum_grads.append((sum_grad, var))\n",
        "  return sum_grads\n",
        "\n",
        "\n",
        "def _add_gradients_summaries(grads_and_vars):\n",
        "  \"\"\"Add histogram summaries to gradients.\n",
        "  Note: The summaries are also added to the SUMMARIES collection.\n",
        "  Args:\n",
        "    grads_and_vars: A list of gradient to variable pairs (tuples).\n",
        "  Returns:\n",
        "    The _list_ of the added summaries for grads_and_vars.\n",
        "  \"\"\"\n",
        "  summaries = []\n",
        "  for grad, var in grads_and_vars:\n",
        "    if grad is not None:\n",
        "      if isinstance(grad, tf.IndexedSlices):\n",
        "        grad_values = grad.values\n",
        "      else:\n",
        "        grad_values = grad\n",
        "      summaries.append(tf.summary.histogram(var.op.name + ':gradient',\n",
        "                                            grad_values))\n",
        "      summaries.append(tf.summary.histogram(var.op.name + ':gradient_norm',\n",
        "                                            tf.global_norm([grad_values])))\n",
        "    else:\n",
        "      tf.logging.info('Var %s has no gradient', var.op.name)\n",
        "  return summaries\n",
        "\n",
        "\n",
        "class DeploymentConfig(object):\n",
        "  \"\"\"Configuration for deploying a model with `deploy()`.\n",
        "  You can pass an instance of this class to `deploy()` to specify exactly\n",
        "  how to deploy the model to build.  If you do not pass one, an instance built\n",
        "  from the default deployment_hparams will be used.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               num_clones=1,\n",
        "               clone_on_cpu=False,\n",
        "               replica_id=0,\n",
        "               num_replicas=1,\n",
        "               num_ps_tasks=0,\n",
        "               worker_job_name='worker',\n",
        "               ps_job_name='ps'):\n",
        "    \"\"\"Create a DeploymentConfig.\n",
        "    The config describes how to deploy a model across multiple clones and\n",
        "    replicas.  The model will be replicated `num_clones` times in each replica.\n",
        "    If `clone_on_cpu` is True, each clone will placed on CPU.\n",
        "    If `num_replicas` is 1, the model is deployed via a single process.  In that\n",
        "    case `worker_device`, `num_ps_tasks`, and `ps_device` are ignored.\n",
        "    If `num_replicas` is greater than 1, then `worker_device` and `ps_device`\n",
        "    must specify TensorFlow devices for the `worker` and `ps` jobs and\n",
        "    `num_ps_tasks` must be positive.\n",
        "    Args:\n",
        "      num_clones: Number of model clones to deploy in each replica.\n",
        "      clone_on_cpu: If True clones would be placed on CPU.\n",
        "      replica_id: Integer.  Index of the replica for which the model is\n",
        "        deployed.  Usually 0 for the chief replica.\n",
        "      num_replicas: Number of replicas to use.\n",
        "      num_ps_tasks: Number of tasks for the `ps` job. 0 to not use replicas.\n",
        "      worker_job_name: A name for the worker job.\n",
        "      ps_job_name: A name for the parameter server job.\n",
        "    Raises:\n",
        "      ValueError: If the arguments are invalid.\n",
        "    \"\"\"\n",
        "    if num_replicas > 1:\n",
        "      if num_ps_tasks < 1:\n",
        "        raise ValueError('When using replicas num_ps_tasks must be positive')\n",
        "    if num_replicas > 1 or num_ps_tasks > 0:\n",
        "      if not worker_job_name:\n",
        "        raise ValueError('Must specify worker_job_name when using replicas')\n",
        "      if not ps_job_name:\n",
        "        raise ValueError('Must specify ps_job_name when using parameter server')\n",
        "    if replica_id >= num_replicas:\n",
        "      raise ValueError('replica_id must be less than num_replicas')\n",
        "    self._num_clones = num_clones\n",
        "    self._clone_on_cpu = clone_on_cpu\n",
        "    self._replica_id = replica_id\n",
        "    self._num_replicas = num_replicas\n",
        "    self._num_ps_tasks = num_ps_tasks\n",
        "    self._ps_device = '/job:' + ps_job_name if num_ps_tasks > 0 else ''\n",
        "    self._worker_device = '/job:' + worker_job_name if num_ps_tasks > 0 else ''\n",
        "\n",
        "  @property\n",
        "  def num_clones(self):\n",
        "    return self._num_clones\n",
        "\n",
        "  @property\n",
        "  def clone_on_cpu(self):\n",
        "    return self._clone_on_cpu\n",
        "\n",
        "  @property\n",
        "  def replica_id(self):\n",
        "    return self._replica_id\n",
        "\n",
        "  @property\n",
        "  def num_replicas(self):\n",
        "    return self._num_replicas\n",
        "\n",
        "  @property\n",
        "  def num_ps_tasks(self):\n",
        "    return self._num_ps_tasks\n",
        "\n",
        "  @property\n",
        "  def ps_device(self):\n",
        "    return self._ps_device\n",
        "\n",
        "  @property\n",
        "  def worker_device(self):\n",
        "    return self._worker_device\n",
        "\n",
        "  def caching_device(self):\n",
        "    \"\"\"Returns the device to use for caching variables.\n",
        "    Variables are cached on the worker CPU when using replicas.\n",
        "    Returns:\n",
        "      A device string or None if the variables do not need to be cached.\n",
        "    \"\"\"\n",
        "    if self._num_ps_tasks > 0:\n",
        "      return lambda op: op.device\n",
        "    else:\n",
        "      return None\n",
        "\n",
        "  def clone_device(self, clone_index):\n",
        "    \"\"\"Device used to create the clone and all the ops inside the clone.\n",
        "    Args:\n",
        "      clone_index: Int, representing the clone_index.\n",
        "    Returns:\n",
        "      A value suitable for `tf.device()`.\n",
        "    Raises:\n",
        "      ValueError: if `clone_index` is greater or equal to the number of clones\".\n",
        "    \"\"\"\n",
        "    if clone_index >= self._num_clones:\n",
        "      raise ValueError('clone_index must be less than num_clones')\n",
        "    device = ''\n",
        "    if self._num_ps_tasks > 0:\n",
        "      device += self._worker_device\n",
        "    if self._clone_on_cpu:\n",
        "      device += '/device:CPU:0'\n",
        "    else:\n",
        "      if self._num_clones > 1:\n",
        "        device += '/device:GPU:%d' % clone_index\n",
        "    return device\n",
        "\n",
        "  def clone_scope(self, clone_index):\n",
        "    \"\"\"Name scope to create the clone.\n",
        "    Args:\n",
        "      clone_index: Int, representing the clone_index.\n",
        "    Returns:\n",
        "      A name_scope suitable for `tf.name_scope()`.\n",
        "    Raises:\n",
        "      ValueError: if `clone_index` is greater or equal to the number of clones\".\n",
        "    \"\"\"\n",
        "    if clone_index >= self._num_clones:\n",
        "      raise ValueError('clone_index must be less than num_clones')\n",
        "    scope = ''\n",
        "    if self._num_clones > 1:\n",
        "      scope = 'clone_%d' % clone_index\n",
        "    return scope\n",
        "\n",
        "  def optimizer_device(self):\n",
        "    \"\"\"Device to use with the optimizer.\n",
        "    Returns:\n",
        "      A value suitable for `tf.device()`.\n",
        "    \"\"\"\n",
        "    if self._num_ps_tasks > 0 or self._num_clones > 0:\n",
        "      return self._worker_device + '/device:CPU:0'\n",
        "    else:\n",
        "      return ''\n",
        "\n",
        "  def inputs_device(self):\n",
        "    \"\"\"Device to use to build the inputs.\n",
        "    Returns:\n",
        "      A value suitable for `tf.device()`.\n",
        "    \"\"\"\n",
        "    device = ''\n",
        "    if self._num_ps_tasks > 0:\n",
        "      device += self._worker_device\n",
        "    device += '/device:CPU:0'\n",
        "    return device\n",
        "\n",
        "  def variables_device(self):\n",
        "    \"\"\"Returns the device to use for variables created inside the clone.\n",
        "    Returns:\n",
        "      A value suitable for `tf.device()`.\n",
        "    \"\"\"\n",
        "    device = ''\n",
        "    if self._num_ps_tasks > 0:\n",
        "      device += self._ps_device\n",
        "    device += '/device:CPU:0'\n",
        "\n",
        "    class _PSDeviceChooser(object):\n",
        "      \"\"\"Slim device chooser for variables when using PS.\"\"\"\n",
        "\n",
        "      def __init__(self, device, tasks):\n",
        "        self._device = device\n",
        "        self._tasks = tasks\n",
        "        self._task = 0\n",
        "\n",
        "      def choose(self, op):\n",
        "        if op.device:\n",
        "          return op.device\n",
        "        node_def = op if isinstance(op, tf.NodeDef) else op.node_def\n",
        "        if node_def.op == 'Variable':\n",
        "          t = self._task\n",
        "          self._task = (self._task + 1) % self._tasks\n",
        "          d = '%s/task:%d' % (self._device, t)\n",
        "          return d\n",
        "        else:\n",
        "          return op.device\n",
        "\n",
        "    if not self._num_ps_tasks:\n",
        "      return device\n",
        "    else:\n",
        "      chooser = _PSDeviceChooser(device, self._num_ps_tasks)\n",
        "      return chooser.choose"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}