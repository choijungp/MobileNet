{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\"\"\"Provides utilities to preprocess images.\n",
        "The preprocessing steps for VGG were introduced in the following technical\n",
        "report:\n",
        "  Very Deep Convolutional Networks For Large-Scale Image Recognition\n",
        "  Karen Simonyan and Andrew Zisserman\n",
        "  arXiv technical report, 2015\n",
        "  PDF: http://arxiv.org/pdf/1409.1556.pdf\n",
        "  ILSVRC 2014 Slides: http://www.robots.ox.ac.uk/~karen/pdf/ILSVRC_2014.pdf\n",
        "  CC-BY-4.0\n",
        "More information can be obtained from the VGG website:\n",
        "www.robots.ox.ac.uk/~vgg/research/very_deep/\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.python.ops import control_flow_ops\n",
        "\n",
        "slim = tf.contrib.slim\n",
        "\n",
        "_R_MEAN = 123.68\n",
        "_G_MEAN = 116.78\n",
        "_B_MEAN = 103.94\n",
        "\n",
        "_RESIZE_SIDE_MIN = 256\n",
        "_RESIZE_SIDE_MAX = 512\n",
        "\n",
        "\n",
        "def _crop(image, offset_height, offset_width, crop_height, crop_width):\n",
        "  \"\"\"Crops the given image using the provided offsets and sizes.\n",
        "  Note that the method doesn't assume we know the input image size but it does\n",
        "  assume we know the input image rank.\n",
        "  Args:\n",
        "    image: an image of shape [height, width, channels].\n",
        "    offset_height: a scalar tensor indicating the height offset.\n",
        "    offset_width: a scalar tensor indicating the width offset.\n",
        "    crop_height: the height of the cropped image.\n",
        "    crop_width: the width of the cropped image.\n",
        "  Returns:\n",
        "    the cropped (and resized) image.\n",
        "  Raises:\n",
        "    InvalidArgumentError: if the rank is not 3 or if the image dimensions are\n",
        "      less than the crop size.\n",
        "  \"\"\"\n",
        "  original_shape = tf.shape(image)\n",
        "\n",
        "  rank_assertion = tf.Assert(\n",
        "      tf.equal(tf.rank(image), 3),\n",
        "      ['Rank of image must be equal to 3.'])\n",
        "  cropped_shape = control_flow_ops.with_dependencies(\n",
        "      [rank_assertion],\n",
        "      tf.stack([crop_height, crop_width, original_shape[2]]))\n",
        "\n",
        "  size_assertion = tf.Assert(\n",
        "      tf.logical_and(\n",
        "          tf.greater_equal(original_shape[0], crop_height),\n",
        "          tf.greater_equal(original_shape[1], crop_width)),\n",
        "      ['Crop size greater than the image size.'])\n",
        "\n",
        "  offsets = tf.to_int32(tf.stack([offset_height, offset_width, 0]))\n",
        "\n",
        "  # Use tf.slice instead of crop_to_bounding box as it accepts tensors to\n",
        "  # define the crop size.\n",
        "  image = control_flow_ops.with_dependencies(\n",
        "      [size_assertion],\n",
        "      tf.slice(image, offsets, cropped_shape))\n",
        "  return tf.reshape(image, cropped_shape)\n",
        "\n",
        "\n",
        "def _random_crop(image_list, crop_height, crop_width):\n",
        "  \"\"\"Crops the given list of images.\n",
        "  The function applies the same crop to each image in the list. This can be\n",
        "  effectively applied when there are multiple image inputs of the same\n",
        "  dimension such as:\n",
        "    image, depths, normals = _random_crop([image, depths, normals], 120, 150)\n",
        "  Args:\n",
        "    image_list: a list of image tensors of the same dimension but possibly\n",
        "      varying channel.\n",
        "    crop_height: the new height.\n",
        "    crop_width: the new width.\n",
        "  Returns:\n",
        "    the image_list with cropped images.\n",
        "  Raises:\n",
        "    ValueError: if there are multiple image inputs provided with different size\n",
        "      or the images are smaller than the crop dimensions.\n",
        "  \"\"\"\n",
        "  if not image_list:\n",
        "    raise ValueError('Empty image_list.')\n",
        "\n",
        "  # Compute the rank assertions.\n",
        "  rank_assertions = []\n",
        "  for i in range(len(image_list)):\n",
        "    image_rank = tf.rank(image_list[i])\n",
        "    rank_assert = tf.Assert(\n",
        "        tf.equal(image_rank, 3),\n",
        "        ['Wrong rank for tensor  %s [expected] [actual]',\n",
        "         image_list[i].name, 3, image_rank])\n",
        "    rank_assertions.append(rank_assert)\n",
        "\n",
        "  image_shape = control_flow_ops.with_dependencies(\n",
        "      [rank_assertions[0]],\n",
        "      tf.shape(image_list[0]))\n",
        "  image_height = image_shape[0]\n",
        "  image_width = image_shape[1]\n",
        "  crop_size_assert = tf.Assert(\n",
        "      tf.logical_and(\n",
        "          tf.greater_equal(image_height, crop_height),\n",
        "          tf.greater_equal(image_width, crop_width)),\n",
        "      ['Crop size greater than the image size.'])\n",
        "\n",
        "  asserts = [rank_assertions[0], crop_size_assert]\n",
        "\n",
        "  for i in range(1, len(image_list)):\n",
        "    image = image_list[i]\n",
        "    asserts.append(rank_assertions[i])\n",
        "    shape = control_flow_ops.with_dependencies([rank_assertions[i]],\n",
        "                                               tf.shape(image))\n",
        "    height = shape[0]\n",
        "    width = shape[1]\n",
        "\n",
        "    height_assert = tf.Assert(\n",
        "        tf.equal(height, image_height),\n",
        "        ['Wrong height for tensor %s [expected][actual]',\n",
        "         image.name, height, image_height])\n",
        "    width_assert = tf.Assert(\n",
        "        tf.equal(width, image_width),\n",
        "        ['Wrong width for tensor %s [expected][actual]',\n",
        "         image.name, width, image_width])\n",
        "    asserts.extend([height_assert, width_assert])\n",
        "\n",
        "  # Create a random bounding box.\n",
        "  #\n",
        "  # Use tf.random_uniform and not numpy.random.rand as doing the former would\n",
        "  # generate random numbers at graph eval time, unlike the latter which\n",
        "  # generates random numbers at graph definition time.\n",
        "  max_offset_height = control_flow_ops.with_dependencies(\n",
        "      asserts, tf.reshape(image_height - crop_height + 1, []))\n",
        "  max_offset_width = control_flow_ops.with_dependencies(\n",
        "      asserts, tf.reshape(image_width - crop_width + 1, []))\n",
        "  offset_height = tf.random_uniform(\n",
        "      [], maxval=max_offset_height, dtype=tf.int32)\n",
        "  offset_width = tf.random_uniform(\n",
        "      [], maxval=max_offset_width, dtype=tf.int32)\n",
        "\n",
        "  return [_crop(image, offset_height, offset_width,\n",
        "                crop_height, crop_width) for image in image_list]\n",
        "\n",
        "\n",
        "def _central_crop(image_list, crop_height, crop_width):\n",
        "  \"\"\"Performs central crops of the given image list.\n",
        "  Args:\n",
        "    image_list: a list of image tensors of the same dimension but possibly\n",
        "      varying channel.\n",
        "    crop_height: the height of the image following the crop.\n",
        "    crop_width: the width of the image following the crop.\n",
        "  Returns:\n",
        "    the list of cropped images.\n",
        "  \"\"\"\n",
        "  outputs = []\n",
        "  for image in image_list:\n",
        "    image_height = tf.shape(image)[0]\n",
        "    image_width = tf.shape(image)[1]\n",
        "\n",
        "    offset_height = (image_height - crop_height) / 2\n",
        "    offset_width = (image_width - crop_width) / 2\n",
        "\n",
        "    outputs.append(_crop(image, offset_height, offset_width,\n",
        "                         crop_height, crop_width))\n",
        "  return outputs\n",
        "\n",
        "\n",
        "def _mean_image_subtraction(image, means):\n",
        "  \"\"\"Subtracts the given means from each image channel.\n",
        "  For example:\n",
        "    means = [123.68, 116.779, 103.939]\n",
        "    image = _mean_image_subtraction(image, means)\n",
        "  Note that the rank of `image` must be known.\n",
        "  Args:\n",
        "    image: a tensor of size [height, width, C].\n",
        "    means: a C-vector of values to subtract from each channel.\n",
        "  Returns:\n",
        "    the centered image.\n",
        "  Raises:\n",
        "    ValueError: If the rank of `image` is unknown, if `image` has a rank other\n",
        "      than three or if the number of channels in `image` doesn't match the\n",
        "      number of values in `means`.\n",
        "  \"\"\"\n",
        "  if image.get_shape().ndims != 3:\n",
        "    raise ValueError('Input must be of size [height, width, C>0]')\n",
        "  num_channels = image.get_shape().as_list()[-1]\n",
        "  if len(means) != num_channels:\n",
        "    raise ValueError('len(means) must match the number of channels')\n",
        "\n",
        "  channels = tf.split(axis=2, num_or_size_splits=num_channels, value=image)\n",
        "  for i in range(num_channels):\n",
        "    channels[i] -= means[i]\n",
        "  return tf.concat(axis=2, values=channels)\n",
        "\n",
        "\n",
        "def _smallest_size_at_least(height, width, smallest_side):\n",
        "  \"\"\"Computes new shape with the smallest side equal to `smallest_side`.\n",
        "  Computes new shape with the smallest side equal to `smallest_side` while\n",
        "  preserving the original aspect ratio.\n",
        "  Args:\n",
        "    height: an int32 scalar tensor indicating the current height.\n",
        "    width: an int32 scalar tensor indicating the current width.\n",
        "    smallest_side: A python integer or scalar `Tensor` indicating the size of\n",
        "      the smallest side after resize.\n",
        "  Returns:\n",
        "    new_height: an int32 scalar tensor indicating the new height.\n",
        "    new_width: and int32 scalar tensor indicating the new width.\n",
        "  \"\"\"\n",
        "  smallest_side = tf.convert_to_tensor(smallest_side, dtype=tf.int32)\n",
        "\n",
        "  height = tf.to_float(height)\n",
        "  width = tf.to_float(width)\n",
        "  smallest_side = tf.to_float(smallest_side)\n",
        "\n",
        "  scale = tf.cond(tf.greater(height, width),\n",
        "                  lambda: smallest_side / width,\n",
        "                  lambda: smallest_side / height)\n",
        "  new_height = tf.to_int32(height * scale)\n",
        "  new_width = tf.to_int32(width * scale)\n",
        "  return new_height, new_width\n",
        "\n",
        "\n",
        "def _aspect_preserving_resize(image, smallest_side):\n",
        "  \"\"\"Resize images preserving the original aspect ratio.\n",
        "  Args:\n",
        "    image: A 3-D image `Tensor`.\n",
        "    smallest_side: A python integer or scalar `Tensor` indicating the size of\n",
        "      the smallest side after resize.\n",
        "  Returns:\n",
        "    resized_image: A 3-D tensor containing the resized image.\n",
        "  \"\"\"\n",
        "  smallest_side = tf.convert_to_tensor(smallest_side, dtype=tf.int32)\n",
        "\n",
        "  shape = tf.shape(image)\n",
        "  height = shape[0]\n",
        "  width = shape[1]\n",
        "  new_height, new_width = _smallest_size_at_least(height, width, smallest_side)\n",
        "  image = tf.expand_dims(image, 0)\n",
        "  resized_image = tf.image.resize_bilinear(image, [new_height, new_width],\n",
        "                                           align_corners=False)\n",
        "  resized_image = tf.squeeze(resized_image)\n",
        "  resized_image.set_shape([None, None, 3])\n",
        "  return resized_image\n",
        "\n",
        "\n",
        "def preprocess_for_train(image,\n",
        "                         output_height,\n",
        "                         output_width,\n",
        "                         resize_side_min=_RESIZE_SIDE_MIN,\n",
        "                         resize_side_max=_RESIZE_SIDE_MAX):\n",
        "  \"\"\"Preprocesses the given image for training.\n",
        "  Note that the actual resizing scale is sampled from\n",
        "    [`resize_size_min`, `resize_size_max`].\n",
        "  Args:\n",
        "    image: A `Tensor` representing an image of arbitrary size.\n",
        "    output_height: The height of the image after preprocessing.\n",
        "    output_width: The width of the image after preprocessing.\n",
        "    resize_side_min: The lower bound for the smallest side of the image for\n",
        "      aspect-preserving resizing.\n",
        "    resize_side_max: The upper bound for the smallest side of the image for\n",
        "      aspect-preserving resizing.\n",
        "  Returns:\n",
        "    A preprocessed image.\n",
        "  \"\"\"\n",
        "  resize_side = tf.random_uniform(\n",
        "      [], minval=resize_side_min, maxval=resize_side_max+1, dtype=tf.int32)\n",
        "\n",
        "  image = _aspect_preserving_resize(image, resize_side)\n",
        "  image = _random_crop([image], output_height, output_width)[0]\n",
        "  image.set_shape([output_height, output_width, 3])\n",
        "  image = tf.to_float(image)\n",
        "  image = tf.image.random_flip_left_right(image)\n",
        "  return _mean_image_subtraction(image, [_R_MEAN, _G_MEAN, _B_MEAN])\n",
        "\n",
        "\n",
        "def preprocess_for_eval(image, output_height, output_width, resize_side):\n",
        "  \"\"\"Preprocesses the given image for evaluation.\n",
        "  Args:\n",
        "    image: A `Tensor` representing an image of arbitrary size.\n",
        "    output_height: The height of the image after preprocessing.\n",
        "    output_width: The width of the image after preprocessing.\n",
        "    resize_side: The smallest side of the image for aspect-preserving resizing.\n",
        "  Returns:\n",
        "    A preprocessed image.\n",
        "  \"\"\"\n",
        "  image = _aspect_preserving_resize(image, resize_side)\n",
        "  image = _central_crop([image], output_height, output_width)[0]\n",
        "  image.set_shape([output_height, output_width, 3])\n",
        "  image = tf.to_float(image)\n",
        "  return _mean_image_subtraction(image, [_R_MEAN, _G_MEAN, _B_MEAN])\n",
        "\n",
        "\n",
        "def preprocess_image(image, output_height, output_width, is_training=False,\n",
        "                     resize_side_min=_RESIZE_SIDE_MIN,\n",
        "                     resize_side_max=_RESIZE_SIDE_MAX):\n",
        "  \"\"\"Preprocesses the given image.\n",
        "  Args:\n",
        "    image: A `Tensor` representing an image of arbitrary size.\n",
        "    output_height: The height of the image after preprocessing.\n",
        "    output_width: The width of the image after preprocessing.\n",
        "    is_training: `True` if we're preprocessing the image for training and\n",
        "      `False` otherwise.\n",
        "    resize_side_min: The lower bound for the smallest side of the image for\n",
        "      aspect-preserving resizing. If `is_training` is `False`, then this value\n",
        "      is used for rescaling.\n",
        "    resize_side_max: The upper bound for the smallest side of the image for\n",
        "      aspect-preserving resizing. If `is_training` is `False`, this value is\n",
        "      ignored. Otherwise, the resize side is sampled from\n",
        "        [resize_size_min, resize_size_max].\n",
        "  Returns:\n",
        "    A preprocessed image.\n",
        "  \"\"\"\n",
        "  if is_training:\n",
        "    return preprocess_for_train(image, output_height, output_width,\n",
        "                                resize_side_min, resize_side_max)\n",
        "  else:\n",
        "    return preprocess_for_eval(image, output_height, output_width,\n",
        "                               resize_side_min)"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}