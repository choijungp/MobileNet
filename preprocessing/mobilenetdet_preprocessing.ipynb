{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\"\"\"Provides utilities to preprocess images for the MobileNet networks.\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.ops import control_flow_ops\n",
        "from preprocessing import tf_image\n",
        "\n",
        "def apply_with_random_selector(x, func, num_cases):\n",
        "  \"\"\"Computes func(x, sel), with sel sampled from [0...num_cases-1].\n",
        "  Args:\n",
        "    x: input Tensor.\n",
        "    func: Python function to apply.\n",
        "    num_cases: Python int32, number of cases to sample sel from.\n",
        "  Returns:\n",
        "    The result of func(x, sel), where func receives the value of the\n",
        "    selector as a python integer, but sel is sampled dynamically.\n",
        "  \"\"\"\n",
        "  sel = tf.random_uniform([], maxval=num_cases, dtype=tf.int32)\n",
        "  # Pass the real x only to one of the func calls.\n",
        "  return control_flow_ops.merge([\n",
        "      func(control_flow_ops.switch(x, tf.equal(sel, case))[1], case)\n",
        "      for case in range(num_cases)])[0]\n",
        "\n",
        "\n",
        "def distort_color(image, color_ordering=0, fast_mode=True, scope=None):\n",
        "  \"\"\"Distort the color of a Tensor image.\n",
        "  Each color distortion is non-commutative and thus ordering of the color ops\n",
        "  matters. Ideally we would randomly permute the ordering of the color ops.\n",
        "  Rather then adding that level of complication, we select a distinct ordering\n",
        "  of color ops for each preprocessing thread.\n",
        "  Args:\n",
        "    image: 3-D Tensor containing single image in [0, 1].\n",
        "    color_ordering: Python int, a type of distortion (valid values: 0-3).\n",
        "    fast_mode: Avoids slower ops (random_hue and random_contrast)\n",
        "    scope: Optional scope for name_scope.\n",
        "  Returns:\n",
        "    3-D Tensor color-distorted image on range [0, 1]\n",
        "  Raises:\n",
        "    ValueError: if color_ordering not in [0, 3]\n",
        "  \"\"\"\n",
        "  with tf.name_scope(scope, 'distort_color', [image]):\n",
        "    if fast_mode:\n",
        "      if color_ordering == 0:\n",
        "        image = tf.image.random_brightness(image, max_delta=32. / 255.)\n",
        "        image = tf.image.random_saturation(image, lower=0.5, upper=1.5)\n",
        "      else:\n",
        "        image = tf.image.random_saturation(image, lower=0.5, upper=1.5)\n",
        "        image = tf.image.random_brightness(image, max_delta=32. / 255.)\n",
        "    else:\n",
        "      if color_ordering == 0:\n",
        "        image = tf.image.random_brightness(image, max_delta=32. / 255.)\n",
        "        image = tf.image.random_saturation(image, lower=0.5, upper=1.5)\n",
        "        image = tf.image.random_hue(image, max_delta=0.2)\n",
        "        image = tf.image.random_contrast(image, lower=0.5, upper=1.5)\n",
        "      elif color_ordering == 1:\n",
        "        image = tf.image.random_saturation(image, lower=0.5, upper=1.5)\n",
        "        image = tf.image.random_brightness(image, max_delta=32. / 255.)\n",
        "        image = tf.image.random_contrast(image, lower=0.5, upper=1.5)\n",
        "        image = tf.image.random_hue(image, max_delta=0.2)\n",
        "      elif color_ordering == 2:\n",
        "        image = tf.image.random_contrast(image, lower=0.5, upper=1.5)\n",
        "        image = tf.image.random_hue(image, max_delta=0.2)\n",
        "        image = tf.image.random_brightness(image, max_delta=32. / 255.)\n",
        "        image = tf.image.random_saturation(image, lower=0.5, upper=1.5)\n",
        "      elif color_ordering == 3:\n",
        "        image = tf.image.random_hue(image, max_delta=0.2)\n",
        "        image = tf.image.random_saturation(image, lower=0.5, upper=1.5)\n",
        "        image = tf.image.random_contrast(image, lower=0.5, upper=1.5)\n",
        "        image = tf.image.random_brightness(image, max_delta=32. / 255.)\n",
        "      else:\n",
        "        raise ValueError('color_ordering must be in [0, 3]')\n",
        "\n",
        "    # The random_* ops do not necessarily clamp.\n",
        "    return tf.clip_by_value(image, 0.0, 1.0)\n",
        "\n",
        "\n",
        "def check_3d_image(image, require_static=True):\n",
        "  \"\"\"Assert that we are working with properly shaped image.\n",
        "  Args:\n",
        "    image: 3-D Tensor of shape [height, width, channels]\n",
        "    require_static: If `True`, requires that all dimensions of `image` are\n",
        "      known and non-zero.\n",
        "  Raises:\n",
        "    ValueError: if `image.shape` is not a 3-vector.\n",
        "  Returns:\n",
        "    An empty list, if `image` has fully defined dimensions. Otherwise, a list\n",
        "    containing an assert op is returned.\n",
        "  \"\"\"\n",
        "  try:\n",
        "    image_shape = image.get_shape().with_rank(3)\n",
        "  except ValueError:\n",
        "    raise ValueError(\"'image' must be three-dimensional.\")\n",
        "  if require_static and not image_shape.is_fully_defined():\n",
        "    raise ValueError(\"'image' must be fully defined.\")\n",
        "  if any(x == 0 for x in image_shape):\n",
        "    raise ValueError(\"all dims of 'image.shape' must be > 0: %s\" %\n",
        "                     image_shape)\n",
        "  if not image_shape.is_fully_defined():\n",
        "    return [tf.assert_positive(tf.shape(image),\n",
        "                                      [\"all dims of 'image.shape' \"\n",
        "                                       \"must be > 0.\"])]\n",
        "  else:\n",
        "    return []\n",
        "\n",
        "\n",
        "def flip_with_bboxes(image, bboxes):\n",
        "  uniform_random = tf.random_uniform([], 0, 1.0)\n",
        "  mirror_cond = tf.less(uniform_random, .5)\n",
        "  stride = tf.where(mirror_cond, -1, 1)\n",
        "\n",
        "  def flip(image, bboxes, stride):\n",
        "    image = image[:, ::stride, :]\n",
        "    img_w = tf.cast(tf.shape(image)[1], dtype=tf.float32)\n",
        "    bbox_coords = tf.unstack(bboxes, num=4, axis=1)\n",
        "    y_min = bbox_coords[0]\n",
        "    x_min = bbox_coords[1]\n",
        "    y_max = bbox_coords[2]\n",
        "    x_max = bbox_coords[3]\n",
        "    x_min_flip = img_w - x_max\n",
        "    x_max_flip = img_w - x_min\n",
        "    bboxes = tf.stack([y_min, x_min_flip, y_max, x_max_flip], 1, name='flip_bboxes')\n",
        "    return image, bboxes\n",
        "\n",
        "  def not_flip(image, bboxes):\n",
        "    return image, bboxes\n",
        "\n",
        "  image_fliped, bboxes = tf.cond(mirror_cond, lambda: flip(image, bboxes, stride), lambda: not_flip(image, bboxes))\n",
        "\n",
        "  return tf_image.fix_image_flip_shape(image, image_fliped), bboxes\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def shift_with_bboxes(image, bboxes):\n",
        "  shift_ratio = 0.2  # TODO(shizehao): remove hard code\n",
        "  image = tf.convert_to_tensor(image)\n",
        "  check_3d_image(image)\n",
        "  img_h, img_w, _ = image.get_shape.aslist()\n",
        "  shift_x = tf.random_uniform([], -shift_ratio, shift_ratio) * img_w\n",
        "  shift_y = tf.random_uniform([], -shift_ratio, shift_ratio) * img_h\n",
        "  tf.image.crop_to_bounding_box()\n",
        "  tf.image.resize_image_with_crop_or_pad()\n",
        "  tf.image.pad_to_bounding_box()\n",
        "  return image, bboxes\n",
        "\"\"\"\n",
        "\n",
        "def preprocess_for_train(image, height, width, labels, bboxes,\n",
        "                         fast_mode=True,\n",
        "                         scope=None):\n",
        "  \"\"\"Distort one image for training a network.\n",
        "  Distorting images provides a useful technique for augmenting the data\n",
        "  set during training in order to make the network invariant to aspects\n",
        "  of the image that do not effect the label.\n",
        "  Additionally it would create image_summaries to display the different\n",
        "  transformations applied to the image.\n",
        "  Args:\n",
        "    image: 3-D Tensor of image. If dtype is tf.float32 then the range should be\n",
        "      [0, 1], otherwise it would converted to tf.float32 assuming that the range\n",
        "      is [0, MAX], where MAX is largest positive representable number for\n",
        "      int(8/16/32) data type (see `tf.image.convert_image_dtype` for details).\n",
        "    height: integer\n",
        "    width: integer\n",
        "    bbox: 3-D float Tensor of bounding boxes arranged [1, num_boxes, coords]\n",
        "      where each coordinate is [0, 1) and the coordinates are arranged\n",
        "      as [ymin, xmin, ymax, xmax].\n",
        "    fast_mode: Optional boolean, if True avoids slower transformations (i.e.\n",
        "      bi-cubic resizing, random_hue or random_contrast).\n",
        "    scope: Optional scope for name_scope.\n",
        "  Returns:\n",
        "    3-D float Tensor of distorted image used for training with range [-1, 1].\n",
        "  \"\"\"\n",
        "  with tf.name_scope(scope, 'distort_image', [image, height, width, bboxes]):\n",
        "    if image.dtype != tf.float32:\n",
        "      image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
        "\n",
        "    tf.summary.image('ori_image',\n",
        "                     tf.expand_dims(image, 0))\n",
        "    # Randomly distort the colors. There are 4 ways to do it.\n",
        "    image = apply_with_random_selector(\n",
        "      image,\n",
        "        lambda x, ordering: distort_color(x, ordering, fast_mode),\n",
        "        num_cases=4)\n",
        "\n",
        "    # Randomly flip the image horizontally.\n",
        "    image, bboxes = flip_with_bboxes(image, bboxes)\n",
        "\n",
        "    print(image.get_shape())\n",
        "\n",
        "    # TODO(shizehao): bistort bbox\n",
        "    image = tf.squeeze(tf.image.resize_nearest_neighbor(tf.expand_dims(image,axis=0),size=[height, width]))\n",
        "\n",
        "    tf.summary.image('final_distorted_image',\n",
        "                     tf.expand_dims(image, 0))\n",
        "\n",
        "    image = tf.subtract(image, 0.5)\n",
        "    image = tf.multiply(image, 2.0)\n",
        "\n",
        "    return image, labels, bboxes\n",
        "\n",
        "\n",
        "def preprocess_for_eval(image, height, width,\n",
        "                        central_fraction=0.875, scope=None):\n",
        "  \"\"\"Prepare one image for evaluation.\n",
        "  If height and width are specified it would output an image with that size by\n",
        "  applying resize_bilinear.\n",
        "  If central_fraction is specified it would cropt the central fraction of the\n",
        "  input image.\n",
        "  Args:\n",
        "    image: 3-D Tensor of image. If dtype is tf.float32 then the range should be\n",
        "      [0, 1], otherwise it would converted to tf.float32 assuming that the range\n",
        "      is [0, MAX], where MAX is largest positive representable number for\n",
        "      int(8/16/32) data type (see `tf.image.convert_image_dtype` for details)\n",
        "    height: integer\n",
        "    width: integer\n",
        "    central_fraction: Optional Float, fraction of the image to crop.\n",
        "    scope: Optional scope for name_scope.\n",
        "  Returns:\n",
        "    3-D float Tensor of prepared image.\n",
        "  \"\"\"\n",
        "  with tf.name_scope(scope, 'eval_image', [image, height, width]):\n",
        "    if image.dtype != tf.float32:\n",
        "      image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
        "    # Crop the central region of the image with an area containing 87.5% of\n",
        "    # the original image.\n",
        "    if central_fraction:\n",
        "      image = tf.image.central_crop(image, central_fraction=central_fraction)\n",
        "\n",
        "    if height and width:\n",
        "      # Resize the image to the specified height and width.\n",
        "      image = tf.expand_dims(image, 0)\n",
        "      image = tf.image.resize_bilinear(image, [height, width],\n",
        "                                       align_corners=False)\n",
        "      image = tf.squeeze(image, [0])\n",
        "    image = tf.subtract(image, 0.5)\n",
        "    image = tf.multiply(image, 2.0)\n",
        "    return image\n",
        "\n",
        "\n",
        "def preprocess_image(image, height, width,\n",
        "                     labels, bboxes,\n",
        "                     is_training=False,\n",
        "                     fast_mode=True):\n",
        "  \"\"\"Pre-process one image for training or evaluation.\n",
        "  Args:\n",
        "    image: 3-D Tensor [height, width, channels] with the image.\n",
        "    height: integer, image expected height.\n",
        "    width: integer, image expected width.\n",
        "    is_training: Boolean. If true it would transform an image for train,\n",
        "      otherwise it would transform it for evaluation.\n",
        "    bbox: 3-D float Tensor of bounding boxes arranged [1, num_boxes, coords]\n",
        "      where each coordinate is [0, 1) and the coordinates are arranged as\n",
        "      [ymin, xmin, ymax, xmax].\n",
        "    fast_mode: Optional boolean, if True avoids slower transformations.\n",
        "  Returns:\n",
        "    3-D float Tensor containing an appropriately scaled image\n",
        "  Raises:\n",
        "    ValueError: if user does not provide bounding box\n",
        "  \"\"\"\n",
        "  if is_training:\n",
        "    return preprocess_for_train(image, height, width, labels, bboxes, fast_mode)\n",
        "  else:\n",
        "    return preprocess_for_eval(image, height, width)"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}